{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment_1_Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX18-pEUVJ2v",
        "outputId": "29ce971b-d380-41d9-e793-311e787e5c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 17)\n",
            "(12800, 16)\n",
            "(12800, 26)\n",
            "(3200, 16)\n",
            "(3200, 26)\n",
            "(4000, 16)\n",
            "(4000, 26)\n",
            "(16, 12800)\n",
            "(26, 12800)\n",
            "(16, 3200)\n",
            "(26, 3200)\n",
            "(16, 4000)\n",
            "(26, 4000)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def create_csv(filepath):\n",
        "    data =  []\n",
        "    with open(filepath) as f:\n",
        "        for val in f.readlines():\n",
        "            val = val.replace(\"\\n\",\"\")\n",
        "            val = val.split(',')\n",
        "            data.append(val)\n",
        "    df = pd.DataFrame(data=data,index=None)\n",
        "    df.to_csv(\"letter_recognition.csv\",index=False)\n",
        "    return df\n",
        "\n",
        "# data = create_csv(\"/content/letter-recognition (1).data\")\n",
        "data = pd.read_csv(\"/content/letter_recognition.csv\").drop(['Unnamed: 0'],axis=1)\n",
        "print(data.shape)\n",
        "\n",
        "# print(data)\n",
        "import sklearn \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "\n",
        "X = data.iloc[:,1:].values.astype(np.float32)\n",
        "Y = data.iloc[:,0].values\n",
        "\n",
        "\n",
        "label_encoder.fit(Y)\n",
        "Y = label_encoder.transform(Y).reshape(-1,1)\n",
        "\n",
        "one_hot_encoder = preprocessing.OneHotEncoder()\n",
        "one_hot_encoder.fit(Y)\n",
        "Y = one_hot_encoder.transform(Y).toarray().astype(np.float32)\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "X_train,X_valid,Y_train,Y_valid = train_test_split(X_train,Y_train,test_size=0.2, random_state=21)\n",
        "\n",
        "np.save(\"X_train.npy\",X_train)\n",
        "np.save(\"Y_train.npy\",Y_train)\n",
        "np.save(\"X_valid.npy\",X_valid)\n",
        "np.save(\"Y_valid.npy\",Y_valid)\n",
        "np.save(\"X_test.npy\",X_test)\n",
        "np.save(\"Y_test.npy\",Y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(Y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "X_train = X_train.T\n",
        "Y_train = Y_train.T\n",
        "X_valid = X_valid.T\n",
        "Y_valid = Y_valid.T\n",
        "X_test = X_test.T\n",
        "Y_test = Y_test.T\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(Y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "\n",
        "#layers_list = dict()\n",
        "h1 = 32\n",
        "h2 = 64\n",
        "h3 = 64\n",
        "\n",
        "def relu_Xavier(a):\n",
        "  return np.sqrt(2/a)\n",
        "\n",
        "def tanh_Xavier(a):\n",
        "  return np.sqrt(1/a)\n",
        "\n",
        "def initialize_parameters(X,Y): \n",
        "\n",
        "    W1 = np.random.randn(h1, X.shape[0])*relu_Xavier(X.shape[0])#tanh_Xavier(X.shape[0]) #\n",
        "    B1 = np.ones((h1, 1))\n",
        "    W2 = np.random.randn(h2, h1)*relu_Xavier(h1) #tanh_Xavier(h1) #  \n",
        "    B2 = np.ones((h2, 1))\n",
        "    W3 = np.random.randn(h3, h2)*relu_Xavier(h2) #tanh_Xavier(h2) #\n",
        "    B3 = np.ones((h3, 1))\n",
        "    W4 = np.random.randn(Y.shape[0], h3)*relu_Xavier(h3) #tanh_Xavier(h3) #\n",
        "    B4 = np.ones((Y.shape[0], 1))\n",
        "    \n",
        "    params = {\n",
        "        \"W1\" : W1,\n",
        "        \"B1\" : B1,\n",
        "        \"W2\" : W2,\n",
        "        \"B2\" : B2,\n",
        "        \"W3\" : W3,\n",
        "        \"B3\" : B3,\n",
        "        \"W4\" : W4,\n",
        "        \"B4\" : B4\n",
        "    }\n",
        "    \n",
        "    return params\n",
        "\n",
        "def initialize_v_s(X,Y):\n",
        "  \n",
        "    v_dW1,v_dB1,s_dW1,s_dB1 = np.zeros((h1, X.shape[0])),np.zeros((h1, 1)),np.zeros((h1, X.shape[0])),np.zeros((h1, 1))\n",
        "    v_dW2,v_dB2,s_dW2,s_dB2 = np.zeros((h2, h1)),np.zeros((h2, 1)),np.zeros((h2,h1)),np.zeros((h2, 1))\n",
        "    v_dW3,v_dB3,s_dW3,s_dB3 = np.zeros((h3, h2)),np.zeros((h3, 1)),np.zeros((h3, h2)),np.zeros((h3, 1))\n",
        "    v_dW4,v_dB4,s_dW4,s_dB4 = np.zeros((Y.shape[0],h3)),np.zeros((Y.shape[0], 1)),np.zeros((Y.shape[0], h3)),np.zeros((Y.shape[0], 1))\n",
        "\n",
        "\n",
        "    v_s = {\n",
        "      \"v_dW4\" : v_dW4,\n",
        "      \"v_dB4\" : v_dB4,\n",
        "      \"s_dW4\" : s_dW4,\n",
        "      \"s_dB4\" : s_dB4,\n",
        "        \n",
        "      \"v_dW3\" : v_dW3,\n",
        "      \"v_dB3\" : v_dB3,\n",
        "      \"s_dW3\" : s_dW3,\n",
        "      \"s_dB3\" : s_dB3,\n",
        "      \n",
        "      \"v_dW2\" : v_dW2,\n",
        "      \"v_dB2\" : v_dB2,\n",
        "      \"s_dW2\" : s_dW2,\n",
        "      \"s_dB2\" : s_dB2,\n",
        "      \n",
        "      \"v_dW1\" : v_dW1,\n",
        "      \"v_dB1\" : v_dB1,\n",
        "      \"s_dW1\" : s_dW1,\n",
        "      \"s_dB1\" : s_dB1\n",
        "    }\n",
        "\n",
        "    return v_s\n",
        "\n",
        "def tanh(a):\n",
        "    return np.tanh(a)\n",
        "\n",
        "def relu(a):\n",
        "    return np.maximum(a, 0)\n",
        "\n",
        "def softmax(a):\n",
        "    expX = np.exp(a)\n",
        "    return expX/np.sum(expX, axis = 0)\n",
        "\n",
        "\n",
        "def forward(X,params):\n",
        "\n",
        "  W1 = params['W1']\n",
        "  B1 = params['B1']\n",
        "  W2 = params['W2']\n",
        "  B2 = params['B2']\n",
        "  W3 = params['W3']\n",
        "  B3 = params['B3']\n",
        "  W4 = params['W4']\n",
        "  B4 = params['B4']\n",
        "\n",
        "\n",
        "  Z1 = np.dot(W1,X)+B1\n",
        "  A1 = relu(Z1)#tanh(Z1)\n",
        "\n",
        "  Z2 = np.dot(W2,A1)+B2\n",
        "  A2 = relu(Z2)#tanh(Z2)\n",
        "\n",
        "  Z3 = np.dot(W3,A2)+B3\n",
        "  A3 = relu(Z3)#tanh(Z3)\n",
        "\n",
        "  Z4 = np.dot(W4,A3)+B4\n",
        "  A4 = softmax(Z4)\n",
        "\n",
        "  forward_cache = {\n",
        "      'Z1':Z1,\n",
        "      'A1':A1,\n",
        "      'Z2':Z2,\n",
        "      'A2':A2,\n",
        "      'Z3':Z3,\n",
        "      'A3':A3,\n",
        "      'Z4':Z4,\n",
        "      'A4':A4,\n",
        "  }\n",
        "\n",
        "  return forward_cache\n",
        "\n",
        "\n",
        "\n",
        "def cost_function(A4,y):\n",
        "  m = y.shape[1]\n",
        "  cost = -(1/m)*np.sum(y*np.log(A4))\n",
        "  return cost\n",
        "\n",
        "\n",
        "def derivative_tanh(a):\n",
        "    return (1 - np.power(np.tanh(a), 2))\n",
        "\n",
        "def derivative_relu(a):\n",
        "    return np.array(a > 0, dtype = np.float32)\n",
        "\n",
        "\n",
        "\n",
        "def backprop(x,y,params,forward_cache):\n",
        "  W1 = params['W1']\n",
        "  B1 = params['B1']\n",
        "  W2 = params['W2']\n",
        "  B2 = params['B2']\n",
        "  W3 = params['W3']\n",
        "  B3 = params['B3']\n",
        "  W4 = params['W4']\n",
        "  B4 = params['B4']\n",
        "  \n",
        "  A1 = forward_cache['A1']\n",
        "  A2 = forward_cache['A2']\n",
        "  A3 = forward_cache['A3']\n",
        "  A4 = forward_cache['A4']\n",
        "\n",
        "  m = x.shape[1]\n",
        "\n",
        "  dZ4 = A4-y\n",
        "  dW4 = (1/m)*np.dot(dZ4,A3.T)\n",
        "  dB4 = (1/m)*np.sum(dZ4,axis=1,keepdims=True)\n",
        "\n",
        "  dZ3 = np.dot(W4.T,dZ4)*derivative_relu(A3) #derivative_tanh(A3) #\n",
        "  dW3 = (1/m)*np.dot(dZ3,A2.T)\n",
        "  dB3 = (1/m)*np.sum(dZ3,axis=1,keepdims=True)\n",
        "\n",
        "  dZ2 = np.dot(W3.T,dZ3)*derivative_relu(A2) #derivative_tanh(A2) #\n",
        "  dW2 = (1/m)*np.dot(dZ2,A1.T)\n",
        "  dB2 = (1/m)*np.sum(dZ2,axis=1,keepdims=True)\n",
        "\n",
        "  dZ1 = np.dot(W2.T,dZ2)*derivative_relu(A1) #derivative_tanh(A1) #\n",
        "  dW1 = (1/m)*np.dot(dZ1,x.T)\n",
        "  dB1 = (1/m)*np.sum(dZ1,axis=1,keepdims=True)\n",
        "\n",
        "\n",
        "  gradients = {\n",
        "        \"dW4\" : dW4,\n",
        "        \"dB4\" : dB4,\n",
        "        \"dW3\" : dW3,\n",
        "        \"dB3\" : dB3,\n",
        "        \"dW2\" : dW2,\n",
        "        \"dB2\" : dB2,\n",
        "        \"dW1\" : dW1,\n",
        "        \"dB1\" : dB1\n",
        "    }\n",
        "\n",
        "  # print(\"gradients:\")\n",
        "  # print(\"dW1:\",dW1,\"\\ndW2:\",dW2,\"\\ndW3:\",dW3,\"\\ndW4:\",dW4)\n",
        "\n",
        "  return gradients\n",
        "\n",
        "\n",
        "def update_parameters(params,v_s,gradients, learning_rate,beta1,beta2,epsilon,batch_no,t):\n",
        "\n",
        "    W4 = params['W4']\n",
        "    B4 = params['B4']\n",
        "    W3 = params['W3']\n",
        "    B3 = params['B3']    \n",
        "    W2 = params['W2']\n",
        "    B2 = params['B2']\n",
        "    W1 = params['W1']\n",
        "    B1 = params['B1']\n",
        "    # print(\"received:\")\n",
        "    # print(\"W1:\",W1,\"\\nW2:\",W2,\"\\nW3:\",W3,\"\\nW4:\",W4)\n",
        "\n",
        "    dW4 = gradients['dW4']\n",
        "    dB4 = gradients['dB4']\n",
        "    dW3 = gradients['dW3']\n",
        "    dB3 = gradients['dB3']\n",
        "    dW2 = gradients['dW2']\n",
        "    dB2 = gradients['dB2']\n",
        "    dW1 = gradients['dW1']\n",
        "    dB1 = gradients['dB1']\n",
        "\n",
        "    v_dW4 = v_s['v_dW4']\n",
        "    v_dB4 = v_s['v_dB4']\n",
        "    s_dW4 = v_s['s_dW4']\n",
        "    s_dB4 = v_s['s_dB4']\n",
        "    v_dW3 = v_s['v_dW3']\n",
        "    v_dB3 = v_s['v_dB3']\n",
        "    s_dW3 = v_s['s_dW3']\n",
        "    s_dB3 = v_s['s_dB3']\n",
        "    v_dW2 = v_s['v_dW2']\n",
        "    v_dB2 = v_s['v_dB2']\n",
        "    s_dW2 = v_s['s_dW2']\n",
        "    s_dB2 = v_s['s_dB2']\n",
        "    v_dW1 = v_s['v_dW1']\n",
        "    v_dB1 = v_s['v_dB1']\n",
        "    s_dW1 = v_s['s_dW1']\n",
        "    s_dB1 = v_s['s_dB1']\n",
        "\n",
        "\n",
        "    # print(\"dW1:\",dW1,\"\\ndW2:\",dW2,\"\\ndW3:\",dW3,\"\\ndW4:\",dW4)\n",
        "    # print(\"batch_no:\",batch_no)\n",
        "\n",
        "    v_dW4 = beta1*v_dW4 + (1-beta1)*dW4\n",
        "    v_dB4 = beta1*v_dB4 + (1-beta1)*dB4\n",
        "    s_dW4 = beta2*s_dW4 + (1-beta2)*(dW4**2)\n",
        "    s_dB4 = beta2*s_dB4 + (1-beta2)*(dB4**2)\n",
        "\n",
        "    v_dW3 = beta1*v_dW3 + (1-beta1)*dW3\n",
        "    v_dB3 = beta1*v_dB3 + (1-beta1)*dB3\n",
        "    s_dW3 = beta2*s_dW3 + (1-beta2)*(dW3**2)\n",
        "    s_dB3 = beta2*s_dB3 + (1-beta2)*(dB3**2)\n",
        "\n",
        "    v_dW2 = beta1*v_dW2 + (1-beta1)*dW2\n",
        "    v_dB2 = beta1*v_dB2 + (1-beta1)*dB2\n",
        "    s_dW2 = beta2*s_dW2 + (1-beta2)*(dW2**2)\n",
        "    s_dB2 = beta2*s_dB2 + (1-beta2)*(dB2**2)\n",
        "\n",
        "    v_dW1 = beta1*v_dW1 + (1-beta1)*dW1\n",
        "    v_dB1 = beta1*v_dB1 + (1-beta1)*dB1\n",
        "    s_dW1 = beta2*s_dW1 + (1-beta2)*(dW1**2)\n",
        "    s_dB1 = beta2*s_dB1 + (1-beta2)*(dB1**2)\n",
        "\n",
        "    v_dW4_corr = v_dW4/(1-beta1**t)\n",
        "    v_dB4_corr = v_dB4/(1-beta1**t)\n",
        "    s_dW4_corr = s_dW4/(1-beta2**t)\n",
        "    s_dB4_corr = s_dB4/(1-beta2**t)\n",
        "\n",
        "    v_dW3_corr = v_dW3/(1-beta1**t)\n",
        "    v_dB3_corr = v_dB3/(1-beta1**t)\n",
        "    s_dW3_corr = s_dW3/(1-beta2**t)\n",
        "    s_dB3_corr = s_dB3/(1-beta2**t)\n",
        "\n",
        "    v_dW2_corr = v_dW2/(1-beta1**t)\n",
        "    v_dB2_corr = v_dB2/(1-beta1**t)\n",
        "    s_dW2_corr = s_dW2/(1-beta2**t)\n",
        "    s_dB2_corr = s_dB2/(1-beta2**t)\n",
        "\n",
        "    v_dW1_corr = v_dW1/(1-beta1**t)\n",
        "    v_dB1_corr = v_dB1/(1-beta1**t)\n",
        "    s_dW1_corr = s_dW1/(1-beta2**t)\n",
        "    s_dB1_corr = s_dB1/(1-beta2**t)\n",
        "\n",
        "    W4 = W4 - learning_rate*(v_dW4_corr/(np.sqrt(s_dW4_corr)+epsilon))\n",
        "    B4 = B4 - learning_rate*(v_dB4_corr/(np.sqrt(s_dB4_corr)+epsilon))\n",
        "    W3 = W3 - learning_rate*(v_dW3_corr/(np.sqrt(s_dW3_corr)+epsilon))\n",
        "    B3 = B3 - learning_rate*(v_dB3_corr/(np.sqrt(s_dB3_corr)+epsilon))\n",
        "    W2 = W2 - learning_rate*(v_dW2_corr/(np.sqrt(s_dW2_corr)+epsilon))\n",
        "    B2 = B2 - learning_rate*(v_dB2_corr/(np.sqrt(s_dB2_corr)+epsilon))\n",
        "    W1 = W1 - learning_rate*(v_dW1_corr/(np.sqrt(s_dW1_corr)+epsilon))\n",
        "    B1 = B1 - learning_rate*(v_dB1_corr/(np.sqrt(s_dB1_corr)+epsilon))\n",
        "\n",
        "    # W4 = W4 - (learning_rate*v_dW4*dW4)/(np.sqrt(s_dW4)+epsilon)\n",
        "    # B4 = B4 - (learning_rate*v_dB4*dB4)/(np.sqrt(s_dB4)+epsilon)\n",
        "    # W3 = W3 - (learning_rate*v_dW3*dW3)/(np.sqrt(s_dW3)+epsilon)\n",
        "    # B3 = B3 - (learning_rate*v_dB3*dB3)/(np.sqrt(s_dB3)+epsilon)\n",
        "    # W2 = W2 - (learning_rate*v_dW2*dW2)/(np.sqrt(s_dW2)+epsilon)\n",
        "    # B2 = B2 - (learning_rate*v_dB2*dB2)/(np.sqrt(s_dB2)+epsilon)\n",
        "    # W1 = W1 - (learning_rate*v_dW1*dW1)/(np.sqrt(s_dW1)+epsilon)\n",
        "    # B1 = B1 - (learning_rate*v_dB1*dB1)/(np.sqrt(s_dB1)+epsilon)\n",
        "    \n",
        "    # print(\"updated:\")\n",
        "    # print(\"W1:\",W1,\"\\nW2:\",W2,\"\\nW3:\",W3,\"\\nW4:\",W4)\n",
        "\n",
        "    \n",
        "    params = {\n",
        "        \"W1\" : W1,\n",
        "        \"B1\" : B1,\n",
        "        \"W2\" : W2,\n",
        "        \"B2\" : B2,\n",
        "        \"W3\" : W3,\n",
        "        \"B3\" : B3,\n",
        "        \"W4\" : W4,\n",
        "        \"B4\" : B4\n",
        "    }\n",
        "\n",
        "    v_s = {\n",
        "        \"v_dW4\" : v_dW4,\n",
        "        \"v_dB4\" : v_dB4,\n",
        "        \"s_dW4\" : s_dW4,\n",
        "        \"s_dB4\" : s_dB4,\n",
        "         \n",
        "        \"v_dW3\" : v_dW3,\n",
        "        \"v_dB3\" : v_dB3,\n",
        "        \"s_dW3\" : s_dW3,\n",
        "        \"s_dB3\" : s_dB3,\n",
        "        \n",
        "        \"v_dW2\" : v_dW2,\n",
        "        \"v_dB2\" : v_dB2,\n",
        "        \"s_dW2\" : s_dW2,\n",
        "        \"s_dB2\" : s_dB2,\n",
        "        \n",
        "        \"v_dW1\" : v_dW1,\n",
        "        \"v_dB1\" : v_dB1,\n",
        "        \"s_dW1\" : s_dW1,\n",
        "        \"s_dB1\" : s_dB1\n",
        "    }\n",
        "\n",
        "    \n",
        "    return params,v_s\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(inp, labels, params):\n",
        "    forward_cache = forward(inp, params)\n",
        "    a_out = forward_cache['A4']   \n",
        "    \n",
        "    a_out = np.argmax(a_out, 0)  \n",
        "    labels = np.argmax(labels, 0)\n",
        "    \n",
        "    \n",
        "    num_correct = np.sum(a_out == labels)\n",
        "    num_incorrect = np.sum(a_out != labels)\n",
        "    acc = (num_correct/(num_correct+num_incorrect)) * 100\n",
        "    return acc,num_correct,num_incorrect\n",
        "\n",
        "\n",
        "def validation_loss_calc(X_valid,Y_valid,params):\n",
        "    batch_size  = 32\n",
        "    num_batches = int(np.ceil(X_valid.shape[1]/batch_size))\n",
        "    ctr = 0\n",
        "    batch_no = 0\n",
        "    running_loss_val = 0.0\n",
        "\n",
        "    while(batch_no!=num_batches):\n",
        "          batch_no += 1\n",
        "          # print(\"batch_no:\",batch_no)\n",
        "        \n",
        "          if batch_no == num_batches:\n",
        "            forward_cache = forward(X_valid[:,ctr:], params)\n",
        "            loss_val = cost_function(forward_cache['A4'], Y_valid[:,ctr:])\n",
        "            running_loss_val += loss_val*(X_valid[:,ctr:].shape[1])\n",
        "          \n",
        "          else:\n",
        "            forward_cache = forward(X_valid[:,ctr:ctr+batch_size], params)\n",
        "            loss_val = cost_function(forward_cache['A4'], Y_valid[:,ctr:ctr+batch_size])\n",
        "            running_loss_val += loss_val*(X_valid[:,ctr:ctr+batch_size].shape[1])\n",
        "            \n",
        "          ctr += batch_size\n",
        " \n",
        "    epoch_val_loss = running_loss_val/float(num_batches*batch_size)\n",
        "\n",
        "    return epoch_val_loss\n",
        "\n",
        "\n",
        "\n",
        "def model(X,Y,X_valid,Y_valid,learning_rate,num_epochs,batch_size,beta1=0.9,beta2=0.999,epsilon=1e-8):\n",
        "    \n",
        "    num_batches = int(np.ceil(X.shape[1]/batch_size))\n",
        "    print(\"num_batches:\",num_batches)\n",
        "    cost_list = []\n",
        "    epoch_val_loss_list = []\n",
        "    epoch_cost_list = []\n",
        "    train_accuracy = []\n",
        "    valid_accuracy = []\n",
        "    t=1\n",
        "\n",
        "    params = initialize_parameters(X,Y) \n",
        "    v_s = initialize_v_s( X,Y)\n",
        "    for epoch in range(num_epochs):\n",
        "      ctr = 0\n",
        "      batch_no = 0\n",
        "      running_loss = 0.0\n",
        "      while(batch_no!=num_batches):\n",
        "          batch_no += 1\n",
        "          # print(\"batch_no:\",batch_no)\n",
        "        \n",
        "          if batch_no == num_batches:\n",
        "            forward_cache = forward(X[:,ctr:], params)\n",
        "            cost = cost_function(forward_cache['A4'], Y[:,ctr:])\n",
        "            gradients = backprop(X[:,ctr:], Y[:,ctr:], params, forward_cache)\n",
        "            running_loss += cost*(X[:,ctr:].shape[1])\n",
        "          \n",
        "          else:\n",
        "            forward_cache = forward(X[:,ctr:ctr+batch_size], params)\n",
        "            cost = cost_function(forward_cache['A4'], Y[:,ctr:ctr+batch_size])\n",
        "            gradients = backprop(X[:,ctr:ctr+batch_size], Y[:,ctr:ctr+batch_size], params, forward_cache)\n",
        "            running_loss += cost*(X[:,ctr:ctr+batch_size].shape[1])\n",
        "            \n",
        "          params,v_s = update_parameters(params,v_s,gradients, learning_rate,beta1=beta1,beta2=beta2,epsilon=epsilon,batch_no=batch_no,t=t)\n",
        "          cost_list.append(cost)\n",
        "          ctr += batch_size\n",
        "          t+=1\n",
        "\n",
        "      epoch_val_loss_list.append(validation_loss_calc(X_valid,Y_valid,params))\n",
        "      epoch_cost_list.append(running_loss/float(num_batches*batch_size))\n",
        "      train_acc,train_num_correct,train_num_incorrect = accuracy(X, Y, params)\n",
        "      valid_acc,valid_num_correct,valid_num_incorrect = accuracy(X_valid, Y_valid, params)\n",
        "      train_accuracy.append(train_acc)\n",
        "      valid_accuracy.append(valid_acc)\n",
        "      print(\"epoch completed:\",epoch, \"loss:\",running_loss/X.shape[1],\" Training Accuracy\",train_acc,\"%\",\" train_num_correct:\",train_num_correct,\" train_num_incorrect:\",train_num_incorrect,\" Validation Accuracy\",valid_acc,\"%\", \"valid_num_correct:\",valid_num_correct,\" valid_num_incorrect:\",valid_num_incorrect)\n",
        "    return params, cost_list, epoch_cost_list,train_accuracy,valid_accuracy,epoch_val_loss_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 405 #200 relu 0.0001 lr 90.92% accuracy 405 relu 0.0001 lr 93.42% accuracy\n",
        "                 #200 tanh 0.0001 lr 85.37% accuracy 405 tanh 0.0001 lr 88.27% accuracy\n",
        "                 #200 relu 0.00001 lr 77.82% accuracy 405 relu 0.0001 lr 81.89% accuracy \n",
        "                 #200 tanh 0.00001 lr 66.55% accuracy 405 tanh 0.0001 lr 71.30% accuracy\n",
        "\n",
        "\n",
        "batch_size=32\n",
        "learning_rate = 0.00001 \n",
        "beta1=0.9\n",
        "beta2=0.999\n",
        "epsilon=1e-8\n",
        "\n",
        "params, Cost_list, epoch_cost_list,train_accuracy,valid_accuracy,epoch_val_loss_list = model(X_train, Y_train,X_valid,Y_valid,learning_rate,num_epochs,batch_size,beta1,beta2,epsilon)\n",
        "\n",
        "test_acc,test_num_correct,test_num_incorrect = accuracy(X_test, Y_test, params)\n",
        "print(\" Test Accuracy\",test_acc,\"%\", \"test_num_correct:\",test_num_correct,\" test_num_incorrect:\",test_num_incorrect)\n",
        "\n",
        "e = np.arange(0, num_epochs)\n",
        "plt.plot(e, epoch_cost_list)\n",
        "plt.plot(e,epoch_val_loss_list)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(e,train_accuracy)\n",
        "plt.plot(e,valid_accuracy)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HOFNLosDVQar",
        "outputId": "80749019-c7de-4924-d0d7-342929a6cbe5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_batches: 400\n",
            "epoch completed: 0 loss: 11.364511511195541  Training Accuracy 1.7109375 %  train_num_correct: 219  train_num_incorrect: 12581  Validation Accuracy 2.0 % valid_num_correct: 64  valid_num_incorrect: 3136\n",
            "epoch completed: 1 loss: 8.155668295635964  Training Accuracy 1.5078125 %  train_num_correct: 193  train_num_incorrect: 12607  Validation Accuracy 1.65625 % valid_num_correct: 53  valid_num_incorrect: 3147\n",
            "epoch completed: 2 loss: 6.5985585331712935  Training Accuracy 2.703125 %  train_num_correct: 346  train_num_incorrect: 12454  Validation Accuracy 3.0625 % valid_num_correct: 98  valid_num_incorrect: 3102\n",
            "epoch completed: 3 loss: 5.6422105609526065  Training Accuracy 4.015625 %  train_num_correct: 514  train_num_incorrect: 12286  Validation Accuracy 4.28125 % valid_num_correct: 137  valid_num_incorrect: 3063\n",
            "epoch completed: 4 loss: 4.993446512210538  Training Accuracy 5.3671875 %  train_num_correct: 687  train_num_incorrect: 12113  Validation Accuracy 5.46875 % valid_num_correct: 175  valid_num_incorrect: 3025\n",
            "epoch completed: 5 loss: 4.550790145431521  Training Accuracy 6.484375000000001 %  train_num_correct: 830  train_num_incorrect: 11970  Validation Accuracy 6.281249999999999 % valid_num_correct: 201  valid_num_incorrect: 2999\n",
            "epoch completed: 6 loss: 4.220403662511753  Training Accuracy 7.28125 %  train_num_correct: 932  train_num_incorrect: 11868  Validation Accuracy 7.781250000000001 % valid_num_correct: 249  valid_num_incorrect: 2951\n",
            "epoch completed: 7 loss: 3.9625748429662564  Training Accuracy 8.109375 %  train_num_correct: 1038  train_num_incorrect: 11762  Validation Accuracy 8.5625 % valid_num_correct: 274  valid_num_incorrect: 2926\n",
            "epoch completed: 8 loss: 3.7632758643261752  Training Accuracy 8.6640625 %  train_num_correct: 1109  train_num_incorrect: 11691  Validation Accuracy 9.5 % valid_num_correct: 304  valid_num_incorrect: 2896\n",
            "epoch completed: 9 loss: 3.6111852853538706  Training Accuracy 9.46875 %  train_num_correct: 1212  train_num_incorrect: 11588  Validation Accuracy 10.40625 % valid_num_correct: 333  valid_num_incorrect: 2867\n",
            "epoch completed: 10 loss: 3.4924183363281553  Training Accuracy 10.4765625 %  train_num_correct: 1341  train_num_incorrect: 11459  Validation Accuracy 11.125 % valid_num_correct: 356  valid_num_incorrect: 2844\n",
            "epoch completed: 11 loss: 3.392842633229709  Training Accuracy 11.46875 %  train_num_correct: 1468  train_num_incorrect: 11332  Validation Accuracy 11.59375 % valid_num_correct: 371  valid_num_incorrect: 2829\n",
            "epoch completed: 12 loss: 3.3041142889637167  Training Accuracy 12.3671875 %  train_num_correct: 1583  train_num_incorrect: 11217  Validation Accuracy 12.53125 % valid_num_correct: 401  valid_num_incorrect: 2799\n",
            "epoch completed: 13 loss: 3.222825486348008  Training Accuracy 13.296875 %  train_num_correct: 1702  train_num_incorrect: 11098  Validation Accuracy 13.125 % valid_num_correct: 420  valid_num_incorrect: 2780\n",
            "epoch completed: 14 loss: 3.1476739004193957  Training Accuracy 14.390625000000002 %  train_num_correct: 1842  train_num_incorrect: 10958  Validation Accuracy 14.03125 % valid_num_correct: 449  valid_num_incorrect: 2751\n",
            "epoch completed: 15 loss: 3.077306264502096  Training Accuracy 15.3046875 %  train_num_correct: 1959  train_num_incorrect: 10841  Validation Accuracy 14.9375 % valid_num_correct: 478  valid_num_incorrect: 2722\n",
            "epoch completed: 16 loss: 3.010184822585038  Training Accuracy 16.5078125 %  train_num_correct: 2113  train_num_incorrect: 10687  Validation Accuracy 16.1875 % valid_num_correct: 518  valid_num_incorrect: 2682\n",
            "epoch completed: 17 loss: 2.94575684738855  Training Accuracy 17.8828125 %  train_num_correct: 2289  train_num_incorrect: 10511  Validation Accuracy 17.125 % valid_num_correct: 548  valid_num_incorrect: 2652\n",
            "epoch completed: 18 loss: 2.8831472590003013  Training Accuracy 19.3125 %  train_num_correct: 2472  train_num_incorrect: 10328  Validation Accuracy 18.6875 % valid_num_correct: 598  valid_num_incorrect: 2602\n",
            "epoch completed: 19 loss: 2.821137142994155  Training Accuracy 20.453125 %  train_num_correct: 2618  train_num_incorrect: 10182  Validation Accuracy 20.28125 % valid_num_correct: 649  valid_num_incorrect: 2551\n",
            "epoch completed: 20 loss: 2.7618771379215166  Training Accuracy 21.8203125 %  train_num_correct: 2793  train_num_incorrect: 10007  Validation Accuracy 21.40625 % valid_num_correct: 685  valid_num_incorrect: 2515\n",
            "epoch completed: 21 loss: 2.705870288443384  Training Accuracy 23.015625 %  train_num_correct: 2946  train_num_incorrect: 9854  Validation Accuracy 22.84375 % valid_num_correct: 731  valid_num_incorrect: 2469\n",
            "epoch completed: 22 loss: 2.6526167094996307  Training Accuracy 24.234375 %  train_num_correct: 3102  train_num_incorrect: 9698  Validation Accuracy 23.96875 % valid_num_correct: 767  valid_num_incorrect: 2433\n",
            "epoch completed: 23 loss: 2.60163589147369  Training Accuracy 25.210937500000004 %  train_num_correct: 3227  train_num_incorrect: 9573  Validation Accuracy 24.9375 % valid_num_correct: 798  valid_num_incorrect: 2402\n",
            "epoch completed: 24 loss: 2.553325338205875  Training Accuracy 26.265624999999996 %  train_num_correct: 3362  train_num_incorrect: 9438  Validation Accuracy 25.78125 % valid_num_correct: 825  valid_num_incorrect: 2375\n",
            "epoch completed: 25 loss: 2.50763571006991  Training Accuracy 27.437499999999996 %  train_num_correct: 3512  train_num_incorrect: 9288  Validation Accuracy 26.687499999999996 % valid_num_correct: 854  valid_num_incorrect: 2346\n",
            "epoch completed: 26 loss: 2.464486067579435  Training Accuracy 28.281250000000004 %  train_num_correct: 3620  train_num_incorrect: 9180  Validation Accuracy 27.375 % valid_num_correct: 876  valid_num_incorrect: 2324\n",
            "epoch completed: 27 loss: 2.4239385328715812  Training Accuracy 29.140624999999996 %  train_num_correct: 3730  train_num_incorrect: 9070  Validation Accuracy 28.1875 % valid_num_correct: 902  valid_num_incorrect: 2298\n",
            "epoch completed: 28 loss: 2.385678078274992  Training Accuracy 29.9609375 %  train_num_correct: 3835  train_num_incorrect: 8965  Validation Accuracy 28.96875 % valid_num_correct: 927  valid_num_incorrect: 2273\n",
            "epoch completed: 29 loss: 2.3493882844838643  Training Accuracy 30.875000000000004 %  train_num_correct: 3952  train_num_incorrect: 8848  Validation Accuracy 29.65625 % valid_num_correct: 949  valid_num_incorrect: 2251\n",
            "epoch completed: 30 loss: 2.3147830230755524  Training Accuracy 31.6875 %  train_num_correct: 4056  train_num_incorrect: 8744  Validation Accuracy 30.6875 % valid_num_correct: 982  valid_num_incorrect: 2218\n",
            "epoch completed: 31 loss: 2.2816944301959294  Training Accuracy 32.53125 %  train_num_correct: 4164  train_num_incorrect: 8636  Validation Accuracy 31.25 % valid_num_correct: 1000  valid_num_incorrect: 2200\n",
            "epoch completed: 32 loss: 2.250119333604093  Training Accuracy 33.5234375 %  train_num_correct: 4291  train_num_incorrect: 8509  Validation Accuracy 31.937500000000004 % valid_num_correct: 1022  valid_num_incorrect: 2178\n",
            "epoch completed: 33 loss: 2.220031751850026  Training Accuracy 34.453125 %  train_num_correct: 4410  train_num_incorrect: 8390  Validation Accuracy 32.9375 % valid_num_correct: 1054  valid_num_incorrect: 2146\n",
            "epoch completed: 34 loss: 2.191233612772005  Training Accuracy 35.4296875 %  train_num_correct: 4535  train_num_incorrect: 8265  Validation Accuracy 34.03125 % valid_num_correct: 1089  valid_num_incorrect: 2111\n",
            "epoch completed: 35 loss: 2.1633574433183367  Training Accuracy 36.2265625 %  train_num_correct: 4637  train_num_incorrect: 8163  Validation Accuracy 35.0 % valid_num_correct: 1120  valid_num_incorrect: 2080\n",
            "epoch completed: 36 loss: 2.136542519946141  Training Accuracy 37.03125 %  train_num_correct: 4740  train_num_incorrect: 8060  Validation Accuracy 35.96875 % valid_num_correct: 1151  valid_num_incorrect: 2049\n",
            "epoch completed: 37 loss: 2.1106026508271762  Training Accuracy 37.9609375 %  train_num_correct: 4859  train_num_incorrect: 7941  Validation Accuracy 36.9375 % valid_num_correct: 1182  valid_num_incorrect: 2018\n",
            "epoch completed: 38 loss: 2.0855825696329213  Training Accuracy 38.6171875 %  train_num_correct: 4943  train_num_incorrect: 7857  Validation Accuracy 37.5625 % valid_num_correct: 1202  valid_num_incorrect: 1998\n",
            "epoch completed: 39 loss: 2.0614069456554485  Training Accuracy 39.4375 %  train_num_correct: 5048  train_num_incorrect: 7752  Validation Accuracy 38.375 % valid_num_correct: 1228  valid_num_incorrect: 1972\n",
            "epoch completed: 40 loss: 2.0379324303159856  Training Accuracy 40.3984375 %  train_num_correct: 5171  train_num_incorrect: 7629  Validation Accuracy 39.25 % valid_num_correct: 1256  valid_num_incorrect: 1944\n",
            "epoch completed: 41 loss: 2.015153373262322  Training Accuracy 41.0703125 %  train_num_correct: 5257  train_num_incorrect: 7543  Validation Accuracy 39.71875 % valid_num_correct: 1271  valid_num_incorrect: 1929\n",
            "epoch completed: 42 loss: 1.9930288924096826  Training Accuracy 41.7890625 %  train_num_correct: 5349  train_num_incorrect: 7451  Validation Accuracy 40.59375 % valid_num_correct: 1299  valid_num_incorrect: 1901\n",
            "epoch completed: 43 loss: 1.971616569668008  Training Accuracy 42.515625 %  train_num_correct: 5442  train_num_incorrect: 7358  Validation Accuracy 41.125 % valid_num_correct: 1316  valid_num_incorrect: 1884\n",
            "epoch completed: 44 loss: 1.9507878623864454  Training Accuracy 43.2734375 %  train_num_correct: 5539  train_num_incorrect: 7261  Validation Accuracy 41.8125 % valid_num_correct: 1338  valid_num_incorrect: 1862\n",
            "epoch completed: 45 loss: 1.9303813232682905  Training Accuracy 43.8984375 %  train_num_correct: 5619  train_num_incorrect: 7181  Validation Accuracy 42.25 % valid_num_correct: 1352  valid_num_incorrect: 1848\n",
            "epoch completed: 46 loss: 1.9104354220241515  Training Accuracy 44.578125 %  train_num_correct: 5706  train_num_incorrect: 7094  Validation Accuracy 42.6875 % valid_num_correct: 1366  valid_num_incorrect: 1834\n",
            "epoch completed: 47 loss: 1.890925722543073  Training Accuracy 45.0078125 %  train_num_correct: 5761  train_num_incorrect: 7039  Validation Accuracy 43.3125 % valid_num_correct: 1386  valid_num_incorrect: 1814\n",
            "epoch completed: 48 loss: 1.8719967888987095  Training Accuracy 45.5859375 %  train_num_correct: 5835  train_num_incorrect: 6965  Validation Accuracy 43.90625 % valid_num_correct: 1405  valid_num_incorrect: 1795\n",
            "epoch completed: 49 loss: 1.8536664882567306  Training Accuracy 46.140625 %  train_num_correct: 5906  train_num_incorrect: 6894  Validation Accuracy 44.59375 % valid_num_correct: 1427  valid_num_incorrect: 1773\n",
            "epoch completed: 50 loss: 1.8357791469675768  Training Accuracy 46.765625 %  train_num_correct: 5986  train_num_incorrect: 6814  Validation Accuracy 45.4375 % valid_num_correct: 1454  valid_num_incorrect: 1746\n",
            "epoch completed: 51 loss: 1.8184090735746559  Training Accuracy 47.3671875 %  train_num_correct: 6063  train_num_incorrect: 6737  Validation Accuracy 45.84375 % valid_num_correct: 1467  valid_num_incorrect: 1733\n",
            "epoch completed: 52 loss: 1.8015272777748137  Training Accuracy 47.9765625 %  train_num_correct: 6141  train_num_incorrect: 6659  Validation Accuracy 46.34375 % valid_num_correct: 1483  valid_num_incorrect: 1717\n",
            "epoch completed: 53 loss: 1.7850212397595824  Training Accuracy 48.5703125 %  train_num_correct: 6217  train_num_incorrect: 6583  Validation Accuracy 46.59375 % valid_num_correct: 1491  valid_num_incorrect: 1709\n",
            "epoch completed: 54 loss: 1.768824598128854  Training Accuracy 49.078125 %  train_num_correct: 6282  train_num_incorrect: 6518  Validation Accuracy 46.96875 % valid_num_correct: 1503  valid_num_incorrect: 1697\n",
            "epoch completed: 55 loss: 1.7530168899347862  Training Accuracy 49.5390625 %  train_num_correct: 6341  train_num_incorrect: 6459  Validation Accuracy 47.75 % valid_num_correct: 1528  valid_num_incorrect: 1672\n",
            "epoch completed: 56 loss: 1.7376226842770575  Training Accuracy 50.05468749999999 %  train_num_correct: 6407  train_num_incorrect: 6393  Validation Accuracy 48.21875 % valid_num_correct: 1543  valid_num_incorrect: 1657\n",
            "epoch completed: 57 loss: 1.72266981069667  Training Accuracy 50.4140625 %  train_num_correct: 6453  train_num_incorrect: 6347  Validation Accuracy 48.5625 % valid_num_correct: 1554  valid_num_incorrect: 1646\n",
            "epoch completed: 58 loss: 1.7081441210669615  Training Accuracy 50.8671875 %  train_num_correct: 6511  train_num_incorrect: 6289  Validation Accuracy 49.1875 % valid_num_correct: 1574  valid_num_incorrect: 1626\n",
            "epoch completed: 59 loss: 1.6940162364837912  Training Accuracy 51.34375 %  train_num_correct: 6572  train_num_incorrect: 6228  Validation Accuracy 49.5 % valid_num_correct: 1584  valid_num_incorrect: 1616\n",
            "epoch completed: 60 loss: 1.6801609457640132  Training Accuracy 51.8046875 %  train_num_correct: 6631  train_num_incorrect: 6169  Validation Accuracy 49.84375 % valid_num_correct: 1595  valid_num_incorrect: 1605\n",
            "epoch completed: 61 loss: 1.6665826102692407  Training Accuracy 52.328125 %  train_num_correct: 6698  train_num_incorrect: 6102  Validation Accuracy 50.24999999999999 % valid_num_correct: 1608  valid_num_incorrect: 1592\n",
            "epoch completed: 62 loss: 1.6533227164596411  Training Accuracy 52.6640625 %  train_num_correct: 6741  train_num_incorrect: 6059  Validation Accuracy 51.09375000000001 % valid_num_correct: 1635  valid_num_incorrect: 1565\n",
            "epoch completed: 63 loss: 1.6404224038784272  Training Accuracy 53.11718749999999 %  train_num_correct: 6799  train_num_incorrect: 6001  Validation Accuracy 51.46875 % valid_num_correct: 1647  valid_num_incorrect: 1553\n",
            "epoch completed: 64 loss: 1.6277848376229858  Training Accuracy 53.50781249999999 %  train_num_correct: 6849  train_num_incorrect: 5951  Validation Accuracy 51.96875 % valid_num_correct: 1663  valid_num_incorrect: 1537\n",
            "epoch completed: 65 loss: 1.6154114012202627  Training Accuracy 53.921875 %  train_num_correct: 6902  train_num_incorrect: 5898  Validation Accuracy 52.21875 % valid_num_correct: 1671  valid_num_incorrect: 1529\n",
            "epoch completed: 66 loss: 1.6033658517865195  Training Accuracy 54.32812500000001 %  train_num_correct: 6954  train_num_incorrect: 5846  Validation Accuracy 52.34375 % valid_num_correct: 1675  valid_num_incorrect: 1525\n",
            "epoch completed: 67 loss: 1.5915243105082155  Training Accuracy 54.7734375 %  train_num_correct: 7011  train_num_incorrect: 5789  Validation Accuracy 52.65625000000001 % valid_num_correct: 1685  valid_num_incorrect: 1515\n",
            "epoch completed: 68 loss: 1.5799091309785043  Training Accuracy 55.00000000000001 %  train_num_correct: 7040  train_num_incorrect: 5760  Validation Accuracy 53.03125 % valid_num_correct: 1697  valid_num_incorrect: 1503\n",
            "epoch completed: 69 loss: 1.5684227809873368  Training Accuracy 55.39062500000001 %  train_num_correct: 7090  train_num_incorrect: 5710  Validation Accuracy 53.34375 % valid_num_correct: 1707  valid_num_incorrect: 1493\n",
            "epoch completed: 70 loss: 1.5570813406509654  Training Accuracy 55.6484375 %  train_num_correct: 7123  train_num_incorrect: 5677  Validation Accuracy 53.59374999999999 % valid_num_correct: 1715  valid_num_incorrect: 1485\n",
            "epoch completed: 71 loss: 1.5460044626894176  Training Accuracy 55.97656250000001 %  train_num_correct: 7165  train_num_incorrect: 5635  Validation Accuracy 54.15624999999999 % valid_num_correct: 1733  valid_num_incorrect: 1467\n",
            "epoch completed: 72 loss: 1.535198987752822  Training Accuracy 56.265625 %  train_num_correct: 7202  train_num_incorrect: 5598  Validation Accuracy 54.6875 % valid_num_correct: 1750  valid_num_incorrect: 1450\n",
            "epoch completed: 73 loss: 1.524665398219866  Training Accuracy 56.546875 %  train_num_correct: 7238  train_num_incorrect: 5562  Validation Accuracy 54.71875000000001 % valid_num_correct: 1751  valid_num_incorrect: 1449\n",
            "epoch completed: 74 loss: 1.5143344460086399  Training Accuracy 56.8203125 %  train_num_correct: 7273  train_num_incorrect: 5527  Validation Accuracy 54.96875 % valid_num_correct: 1759  valid_num_incorrect: 1441\n",
            "epoch completed: 75 loss: 1.5041620149144803  Training Accuracy 57.125 %  train_num_correct: 7312  train_num_incorrect: 5488  Validation Accuracy 55.34375 % valid_num_correct: 1771  valid_num_incorrect: 1429\n",
            "epoch completed: 76 loss: 1.4941392436090155  Training Accuracy 57.4375 %  train_num_correct: 7352  train_num_incorrect: 5448  Validation Accuracy 55.75 % valid_num_correct: 1784  valid_num_incorrect: 1416\n",
            "epoch completed: 77 loss: 1.4842542648806063  Training Accuracy 57.7109375 %  train_num_correct: 7387  train_num_incorrect: 5413  Validation Accuracy 56.09375 % valid_num_correct: 1795  valid_num_incorrect: 1405\n",
            "epoch completed: 78 loss: 1.4744774792025481  Training Accuracy 58.08593749999999 %  train_num_correct: 7435  train_num_incorrect: 5365  Validation Accuracy 56.375 % valid_num_correct: 1804  valid_num_incorrect: 1396\n",
            "epoch completed: 79 loss: 1.4648348563667282  Training Accuracy 58.3984375 %  train_num_correct: 7475  train_num_incorrect: 5325  Validation Accuracy 56.71874999999999 % valid_num_correct: 1815  valid_num_incorrect: 1385\n",
            "epoch completed: 80 loss: 1.4553659531028642  Training Accuracy 58.60156250000001 %  train_num_correct: 7501  train_num_incorrect: 5299  Validation Accuracy 56.875 % valid_num_correct: 1820  valid_num_incorrect: 1380\n",
            "epoch completed: 81 loss: 1.4461067670246779  Training Accuracy 58.8984375 %  train_num_correct: 7539  train_num_incorrect: 5261  Validation Accuracy 57.1875 % valid_num_correct: 1830  valid_num_incorrect: 1370\n",
            "epoch completed: 82 loss: 1.437044545185401  Training Accuracy 59.21875 %  train_num_correct: 7580  train_num_incorrect: 5220  Validation Accuracy 57.34375000000001 % valid_num_correct: 1835  valid_num_incorrect: 1365\n",
            "epoch completed: 83 loss: 1.4281668530608045  Training Accuracy 59.57812500000001 %  train_num_correct: 7626  train_num_incorrect: 5174  Validation Accuracy 57.75 % valid_num_correct: 1848  valid_num_incorrect: 1352\n",
            "epoch completed: 84 loss: 1.4194095286050474  Training Accuracy 59.82031249999999 %  train_num_correct: 7657  train_num_incorrect: 5143  Validation Accuracy 57.9375 % valid_num_correct: 1854  valid_num_incorrect: 1346\n",
            "epoch completed: 85 loss: 1.410766225991258  Training Accuracy 60.109375 %  train_num_correct: 7694  train_num_incorrect: 5106  Validation Accuracy 58.4375 % valid_num_correct: 1870  valid_num_incorrect: 1330\n",
            "epoch completed: 86 loss: 1.4021743947578866  Training Accuracy 60.40624999999999 %  train_num_correct: 7732  train_num_incorrect: 5068  Validation Accuracy 58.62500000000001 % valid_num_correct: 1876  valid_num_incorrect: 1324\n",
            "epoch completed: 87 loss: 1.3936580761436048  Training Accuracy 60.71875 %  train_num_correct: 7772  train_num_incorrect: 5028  Validation Accuracy 58.875 % valid_num_correct: 1884  valid_num_incorrect: 1316\n",
            "epoch completed: 88 loss: 1.3853045376244715  Training Accuracy 61.0625 %  train_num_correct: 7816  train_num_incorrect: 4984  Validation Accuracy 59.28125 % valid_num_correct: 1897  valid_num_incorrect: 1303\n",
            "epoch completed: 89 loss: 1.377087112587288  Training Accuracy 61.265625 %  train_num_correct: 7842  train_num_incorrect: 4958  Validation Accuracy 59.40625000000001 % valid_num_correct: 1901  valid_num_incorrect: 1299\n",
            "epoch completed: 90 loss: 1.3689591838286466  Training Accuracy 61.53125000000001 %  train_num_correct: 7876  train_num_incorrect: 4924  Validation Accuracy 59.59375 % valid_num_correct: 1907  valid_num_incorrect: 1293\n",
            "epoch completed: 91 loss: 1.360877737361087  Training Accuracy 61.71093749999999 %  train_num_correct: 7899  train_num_incorrect: 4901  Validation Accuracy 59.9375 % valid_num_correct: 1918  valid_num_incorrect: 1282\n",
            "epoch completed: 92 loss: 1.3529811574737203  Training Accuracy 61.94531250000001 %  train_num_correct: 7929  train_num_incorrect: 4871  Validation Accuracy 60.21875 % valid_num_correct: 1927  valid_num_incorrect: 1273\n",
            "epoch completed: 93 loss: 1.3451809039765201  Training Accuracy 62.265625 %  train_num_correct: 7970  train_num_incorrect: 4830  Validation Accuracy 60.53125 % valid_num_correct: 1937  valid_num_incorrect: 1263\n",
            "epoch completed: 94 loss: 1.3375364890197066  Training Accuracy 62.4140625 %  train_num_correct: 7989  train_num_incorrect: 4811  Validation Accuracy 60.75000000000001 % valid_num_correct: 1944  valid_num_incorrect: 1256\n",
            "epoch completed: 95 loss: 1.3300616849471332  Training Accuracy 62.6796875 %  train_num_correct: 8023  train_num_incorrect: 4777  Validation Accuracy 60.84375 % valid_num_correct: 1947  valid_num_incorrect: 1253\n",
            "epoch completed: 96 loss: 1.3226958662222292  Training Accuracy 62.9296875 %  train_num_correct: 8055  train_num_incorrect: 4745  Validation Accuracy 60.9375 % valid_num_correct: 1950  valid_num_incorrect: 1250\n",
            "epoch completed: 97 loss: 1.3154681152428458  Training Accuracy 63.14062499999999 %  train_num_correct: 8082  train_num_incorrect: 4718  Validation Accuracy 61.0625 % valid_num_correct: 1954  valid_num_incorrect: 1246\n",
            "epoch completed: 98 loss: 1.3083950961048973  Training Accuracy 63.375 %  train_num_correct: 8112  train_num_incorrect: 4688  Validation Accuracy 61.28125 % valid_num_correct: 1961  valid_num_incorrect: 1239\n",
            "epoch completed: 99 loss: 1.3013766897112689  Training Accuracy 63.5859375 %  train_num_correct: 8139  train_num_incorrect: 4661  Validation Accuracy 61.59375 % valid_num_correct: 1971  valid_num_incorrect: 1229\n",
            "epoch completed: 100 loss: 1.2944765142710475  Training Accuracy 63.8203125 %  train_num_correct: 8169  train_num_incorrect: 4631  Validation Accuracy 62.03125000000001 % valid_num_correct: 1985  valid_num_incorrect: 1215\n",
            "epoch completed: 101 loss: 1.2877000696660885  Training Accuracy 64.0625 %  train_num_correct: 8200  train_num_incorrect: 4600  Validation Accuracy 62.21875 % valid_num_correct: 1991  valid_num_incorrect: 1209\n",
            "epoch completed: 102 loss: 1.2809787978583642  Training Accuracy 64.3671875 %  train_num_correct: 8239  train_num_incorrect: 4561  Validation Accuracy 62.375 % valid_num_correct: 1996  valid_num_incorrect: 1204\n",
            "epoch completed: 103 loss: 1.2743311444174434  Training Accuracy 64.671875 %  train_num_correct: 8278  train_num_incorrect: 4522  Validation Accuracy 62.65625 % valid_num_correct: 2005  valid_num_incorrect: 1195\n",
            "epoch completed: 104 loss: 1.267770862318608  Training Accuracy 64.90625 %  train_num_correct: 8308  train_num_incorrect: 4492  Validation Accuracy 62.78125 % valid_num_correct: 2009  valid_num_incorrect: 1191\n",
            "epoch completed: 105 loss: 1.261390116228886  Training Accuracy 65.0625 %  train_num_correct: 8328  train_num_incorrect: 4472  Validation Accuracy 63.0 % valid_num_correct: 2016  valid_num_incorrect: 1184\n",
            "epoch completed: 106 loss: 1.2551291985146675  Training Accuracy 65.359375 %  train_num_correct: 8366  train_num_incorrect: 4434  Validation Accuracy 63.31250000000001 % valid_num_correct: 2026  valid_num_incorrect: 1174\n",
            "epoch completed: 107 loss: 1.2490066299887348  Training Accuracy 65.4921875 %  train_num_correct: 8383  train_num_incorrect: 4417  Validation Accuracy 63.65625 % valid_num_correct: 2037  valid_num_incorrect: 1163\n",
            "epoch completed: 108 loss: 1.2429676823466083  Training Accuracy 65.6953125 %  train_num_correct: 8409  train_num_incorrect: 4391  Validation Accuracy 63.84375 % valid_num_correct: 2043  valid_num_incorrect: 1157\n",
            "epoch completed: 109 loss: 1.2370404202101895  Training Accuracy 65.921875 %  train_num_correct: 8438  train_num_incorrect: 4362  Validation Accuracy 64.125 % valid_num_correct: 2052  valid_num_incorrect: 1148\n",
            "epoch completed: 110 loss: 1.2311686248871185  Training Accuracy 66.1171875 %  train_num_correct: 8463  train_num_incorrect: 4337  Validation Accuracy 64.25 % valid_num_correct: 2056  valid_num_incorrect: 1144\n",
            "epoch completed: 111 loss: 1.2253819724169384  Training Accuracy 66.3984375 %  train_num_correct: 8499  train_num_incorrect: 4301  Validation Accuracy 64.28125 % valid_num_correct: 2057  valid_num_incorrect: 1143\n",
            "epoch completed: 112 loss: 1.2197114641783027  Training Accuracy 66.6328125 %  train_num_correct: 8529  train_num_incorrect: 4271  Validation Accuracy 64.5625 % valid_num_correct: 2066  valid_num_incorrect: 1134\n",
            "epoch completed: 113 loss: 1.2141110510909572  Training Accuracy 66.796875 %  train_num_correct: 8550  train_num_incorrect: 4250  Validation Accuracy 64.8125 % valid_num_correct: 2074  valid_num_incorrect: 1126\n",
            "epoch completed: 114 loss: 1.2086237233327508  Training Accuracy 67.03125 %  train_num_correct: 8580  train_num_incorrect: 4220  Validation Accuracy 65.0625 % valid_num_correct: 2082  valid_num_incorrect: 1118\n",
            "epoch completed: 115 loss: 1.203221271224994  Training Accuracy 67.265625 %  train_num_correct: 8610  train_num_incorrect: 4190  Validation Accuracy 65.28125 % valid_num_correct: 2089  valid_num_incorrect: 1111\n",
            "epoch completed: 116 loss: 1.1978993032035563  Training Accuracy 67.4609375 %  train_num_correct: 8635  train_num_incorrect: 4165  Validation Accuracy 65.5625 % valid_num_correct: 2098  valid_num_incorrect: 1102\n",
            "epoch completed: 117 loss: 1.1926364798174323  Training Accuracy 67.609375 %  train_num_correct: 8654  train_num_incorrect: 4146  Validation Accuracy 65.6875 % valid_num_correct: 2102  valid_num_incorrect: 1098\n",
            "epoch completed: 118 loss: 1.1874336775026806  Training Accuracy 67.7109375 %  train_num_correct: 8667  train_num_incorrect: 4133  Validation Accuracy 65.84375 % valid_num_correct: 2107  valid_num_incorrect: 1093\n",
            "epoch completed: 119 loss: 1.182304036120301  Training Accuracy 67.8515625 %  train_num_correct: 8685  train_num_incorrect: 4115  Validation Accuracy 66.03125 % valid_num_correct: 2113  valid_num_incorrect: 1087\n",
            "epoch completed: 120 loss: 1.1772689475771  Training Accuracy 68.0390625 %  train_num_correct: 8709  train_num_incorrect: 4091  Validation Accuracy 66.3125 % valid_num_correct: 2122  valid_num_incorrect: 1078\n",
            "epoch completed: 121 loss: 1.1722961270607457  Training Accuracy 68.234375 %  train_num_correct: 8734  train_num_incorrect: 4066  Validation Accuracy 66.40625 % valid_num_correct: 2125  valid_num_incorrect: 1075\n",
            "epoch completed: 122 loss: 1.1673956477343679  Training Accuracy 68.3671875 %  train_num_correct: 8751  train_num_incorrect: 4049  Validation Accuracy 66.5 % valid_num_correct: 2128  valid_num_incorrect: 1072\n",
            "epoch completed: 123 loss: 1.162557920670003  Training Accuracy 68.46875 %  train_num_correct: 8764  train_num_incorrect: 4036  Validation Accuracy 66.46875 % valid_num_correct: 2127  valid_num_incorrect: 1073\n",
            "epoch completed: 124 loss: 1.1577891838277021  Training Accuracy 68.6796875 %  train_num_correct: 8791  train_num_incorrect: 4009  Validation Accuracy 66.6875 % valid_num_correct: 2134  valid_num_incorrect: 1066\n",
            "epoch completed: 125 loss: 1.1530904220781297  Training Accuracy 68.8671875 %  train_num_correct: 8815  train_num_incorrect: 3985  Validation Accuracy 66.75 % valid_num_correct: 2136  valid_num_incorrect: 1064\n",
            "epoch completed: 126 loss: 1.1484045119572175  Training Accuracy 69.0 %  train_num_correct: 8832  train_num_incorrect: 3968  Validation Accuracy 66.84375 % valid_num_correct: 2139  valid_num_incorrect: 1061\n",
            "epoch completed: 127 loss: 1.1437519233885645  Training Accuracy 69.078125 %  train_num_correct: 8842  train_num_incorrect: 3958  Validation Accuracy 66.84375 % valid_num_correct: 2139  valid_num_incorrect: 1061\n",
            "epoch completed: 128 loss: 1.1391707682160581  Training Accuracy 69.2109375 %  train_num_correct: 8859  train_num_incorrect: 3941  Validation Accuracy 66.96875 % valid_num_correct: 2143  valid_num_incorrect: 1057\n",
            "epoch completed: 129 loss: 1.134634393982552  Training Accuracy 69.3359375 %  train_num_correct: 8875  train_num_incorrect: 3925  Validation Accuracy 67.09375 % valid_num_correct: 2147  valid_num_incorrect: 1053\n",
            "epoch completed: 130 loss: 1.1301429161731327  Training Accuracy 69.4296875 %  train_num_correct: 8887  train_num_incorrect: 3913  Validation Accuracy 67.34375 % valid_num_correct: 2155  valid_num_incorrect: 1045\n",
            "epoch completed: 131 loss: 1.1257074778044487  Training Accuracy 69.53125 %  train_num_correct: 8900  train_num_incorrect: 3900  Validation Accuracy 67.5 % valid_num_correct: 2160  valid_num_incorrect: 1040\n",
            "epoch completed: 132 loss: 1.1213575213022777  Training Accuracy 69.65625 %  train_num_correct: 8916  train_num_incorrect: 3884  Validation Accuracy 67.75 % valid_num_correct: 2168  valid_num_incorrect: 1032\n",
            "epoch completed: 133 loss: 1.1170672355865099  Training Accuracy 69.75 %  train_num_correct: 8928  train_num_incorrect: 3872  Validation Accuracy 67.78125 % valid_num_correct: 2169  valid_num_incorrect: 1031\n",
            "epoch completed: 134 loss: 1.1127951512844692  Training Accuracy 69.8828125 %  train_num_correct: 8945  train_num_incorrect: 3855  Validation Accuracy 67.96875 % valid_num_correct: 2175  valid_num_incorrect: 1025\n",
            "epoch completed: 135 loss: 1.1085821544146361  Training Accuracy 69.9453125 %  train_num_correct: 8953  train_num_incorrect: 3847  Validation Accuracy 68.15625 % valid_num_correct: 2181  valid_num_incorrect: 1019\n",
            "epoch completed: 136 loss: 1.1044203538839212  Training Accuracy 70.046875 %  train_num_correct: 8966  train_num_incorrect: 3834  Validation Accuracy 68.3125 % valid_num_correct: 2186  valid_num_incorrect: 1014\n",
            "epoch completed: 137 loss: 1.1002991427105462  Training Accuracy 70.1484375 %  train_num_correct: 8979  train_num_incorrect: 3821  Validation Accuracy 68.4375 % valid_num_correct: 2190  valid_num_incorrect: 1010\n",
            "epoch completed: 138 loss: 1.0962007707367036  Training Accuracy 70.2734375 %  train_num_correct: 8995  train_num_incorrect: 3805  Validation Accuracy 68.40625 % valid_num_correct: 2189  valid_num_incorrect: 1011\n",
            "epoch completed: 139 loss: 1.092146278044542  Training Accuracy 70.4296875 %  train_num_correct: 9015  train_num_incorrect: 3785  Validation Accuracy 68.5625 % valid_num_correct: 2194  valid_num_incorrect: 1006\n",
            "epoch completed: 140 loss: 1.088100435440977  Training Accuracy 70.5078125 %  train_num_correct: 9025  train_num_incorrect: 3775  Validation Accuracy 68.5625 % valid_num_correct: 2194  valid_num_incorrect: 1006\n",
            "epoch completed: 141 loss: 1.0841095293553031  Training Accuracy 70.65625 %  train_num_correct: 9044  train_num_incorrect: 3756  Validation Accuracy 68.59375 % valid_num_correct: 2195  valid_num_incorrect: 1005\n",
            "epoch completed: 142 loss: 1.0801593793282387  Training Accuracy 70.7734375 %  train_num_correct: 9059  train_num_incorrect: 3741  Validation Accuracy 68.5625 % valid_num_correct: 2194  valid_num_incorrect: 1006\n",
            "epoch completed: 143 loss: 1.0762393630468787  Training Accuracy 70.8984375 %  train_num_correct: 9075  train_num_incorrect: 3725  Validation Accuracy 68.6875 % valid_num_correct: 2198  valid_num_incorrect: 1002\n",
            "epoch completed: 144 loss: 1.0723584776530086  Training Accuracy 71.0 %  train_num_correct: 9088  train_num_incorrect: 3712  Validation Accuracy 68.78125 % valid_num_correct: 2201  valid_num_incorrect: 999\n",
            "epoch completed: 145 loss: 1.0685325164141677  Training Accuracy 71.1796875 %  train_num_correct: 9111  train_num_incorrect: 3689  Validation Accuracy 68.84375 % valid_num_correct: 2203  valid_num_incorrect: 997\n",
            "epoch completed: 146 loss: 1.0647637681956745  Training Accuracy 71.2421875 %  train_num_correct: 9119  train_num_incorrect: 3681  Validation Accuracy 68.90625 % valid_num_correct: 2205  valid_num_incorrect: 995\n",
            "epoch completed: 147 loss: 1.061013864421188  Training Accuracy 71.34375 %  train_num_correct: 9132  train_num_incorrect: 3668  Validation Accuracy 69.03125 % valid_num_correct: 2209  valid_num_incorrect: 991\n",
            "epoch completed: 148 loss: 1.0573315141441133  Training Accuracy 71.4453125 %  train_num_correct: 9145  train_num_incorrect: 3655  Validation Accuracy 69.09375 % valid_num_correct: 2211  valid_num_incorrect: 989\n",
            "epoch completed: 149 loss: 1.0536972117048016  Training Accuracy 71.5078125 %  train_num_correct: 9153  train_num_incorrect: 3647  Validation Accuracy 69.1875 % valid_num_correct: 2214  valid_num_incorrect: 986\n",
            "epoch completed: 150 loss: 1.05009575170295  Training Accuracy 71.6171875 %  train_num_correct: 9167  train_num_incorrect: 3633  Validation Accuracy 69.15625 % valid_num_correct: 2213  valid_num_incorrect: 987\n",
            "epoch completed: 151 loss: 1.0465412794823707  Training Accuracy 71.75 %  train_num_correct: 9184  train_num_incorrect: 3616  Validation Accuracy 69.25 % valid_num_correct: 2216  valid_num_incorrect: 984\n",
            "epoch completed: 152 loss: 1.0430088938045154  Training Accuracy 71.8828125 %  train_num_correct: 9201  train_num_incorrect: 3599  Validation Accuracy 69.4375 % valid_num_correct: 2222  valid_num_incorrect: 978\n",
            "epoch completed: 153 loss: 1.0395281333480764  Training Accuracy 72.078125 %  train_num_correct: 9226  train_num_incorrect: 3574  Validation Accuracy 69.5625 % valid_num_correct: 2226  valid_num_incorrect: 974\n",
            "epoch completed: 154 loss: 1.0360688391840234  Training Accuracy 72.21875 %  train_num_correct: 9244  train_num_incorrect: 3556  Validation Accuracy 69.65625 % valid_num_correct: 2229  valid_num_incorrect: 971\n",
            "epoch completed: 155 loss: 1.0326490147606462  Training Accuracy 72.34375 %  train_num_correct: 9260  train_num_incorrect: 3540  Validation Accuracy 69.65625 % valid_num_correct: 2229  valid_num_incorrect: 971\n",
            "epoch completed: 156 loss: 1.0292344434583773  Training Accuracy 72.4375 %  train_num_correct: 9272  train_num_incorrect: 3528  Validation Accuracy 69.75 % valid_num_correct: 2232  valid_num_incorrect: 968\n",
            "epoch completed: 157 loss: 1.0258732883552466  Training Accuracy 72.5390625 %  train_num_correct: 9285  train_num_incorrect: 3515  Validation Accuracy 69.875 % valid_num_correct: 2236  valid_num_incorrect: 964\n",
            "epoch completed: 158 loss: 1.022527163137172  Training Accuracy 72.6328125 %  train_num_correct: 9297  train_num_incorrect: 3503  Validation Accuracy 69.90625 % valid_num_correct: 2237  valid_num_incorrect: 963\n",
            "epoch completed: 159 loss: 1.0192152053446606  Training Accuracy 72.7109375 %  train_num_correct: 9307  train_num_incorrect: 3493  Validation Accuracy 70.15625 % valid_num_correct: 2245  valid_num_incorrect: 955\n",
            "epoch completed: 160 loss: 1.0159152079534344  Training Accuracy 72.8125 %  train_num_correct: 9320  train_num_incorrect: 3480  Validation Accuracy 70.28125 % valid_num_correct: 2249  valid_num_incorrect: 951\n",
            "epoch completed: 161 loss: 1.012661386473497  Training Accuracy 72.890625 %  train_num_correct: 9330  train_num_incorrect: 3470  Validation Accuracy 70.4375 % valid_num_correct: 2254  valid_num_incorrect: 946\n",
            "epoch completed: 162 loss: 1.009431250565055  Training Accuracy 72.9375 %  train_num_correct: 9336  train_num_incorrect: 3464  Validation Accuracy 70.5 % valid_num_correct: 2256  valid_num_incorrect: 944\n",
            "epoch completed: 163 loss: 1.0062302740568767  Training Accuracy 73.0703125 %  train_num_correct: 9353  train_num_incorrect: 3447  Validation Accuracy 70.65625 % valid_num_correct: 2261  valid_num_incorrect: 939\n",
            "epoch completed: 164 loss: 1.003090467761227  Training Accuracy 73.1328125 %  train_num_correct: 9361  train_num_incorrect: 3439  Validation Accuracy 70.75 % valid_num_correct: 2264  valid_num_incorrect: 936\n",
            "epoch completed: 165 loss: 0.9999552160308093  Training Accuracy 73.2421875 %  train_num_correct: 9375  train_num_incorrect: 3425  Validation Accuracy 70.75 % valid_num_correct: 2264  valid_num_incorrect: 936\n",
            "epoch completed: 166 loss: 0.996821648301274  Training Accuracy 73.4140625 %  train_num_correct: 9397  train_num_incorrect: 3403  Validation Accuracy 70.875 % valid_num_correct: 2268  valid_num_incorrect: 932\n",
            "epoch completed: 167 loss: 0.9937350037830786  Training Accuracy 73.5 %  train_num_correct: 9408  train_num_incorrect: 3392  Validation Accuracy 70.9375 % valid_num_correct: 2270  valid_num_incorrect: 930\n",
            "epoch completed: 168 loss: 0.9906639829899233  Training Accuracy 73.609375 %  train_num_correct: 9422  train_num_incorrect: 3378  Validation Accuracy 70.90625 % valid_num_correct: 2269  valid_num_incorrect: 931\n",
            "epoch completed: 169 loss: 0.9876002761134469  Training Accuracy 73.65625 %  train_num_correct: 9428  train_num_incorrect: 3372  Validation Accuracy 71.03125 % valid_num_correct: 2273  valid_num_incorrect: 927\n",
            "epoch completed: 170 loss: 0.9845627326311049  Training Accuracy 73.7109375 %  train_num_correct: 9435  train_num_incorrect: 3365  Validation Accuracy 71.09375 % valid_num_correct: 2275  valid_num_incorrect: 925\n",
            "epoch completed: 171 loss: 0.9815678438307621  Training Accuracy 73.78125 %  train_num_correct: 9444  train_num_incorrect: 3356  Validation Accuracy 71.125 % valid_num_correct: 2276  valid_num_incorrect: 924\n",
            "epoch completed: 172 loss: 0.9786077975072679  Training Accuracy 73.8671875 %  train_num_correct: 9455  train_num_incorrect: 3345  Validation Accuracy 71.21875 % valid_num_correct: 2279  valid_num_incorrect: 921\n",
            "epoch completed: 173 loss: 0.9756968310539623  Training Accuracy 74.015625 %  train_num_correct: 9474  train_num_incorrect: 3326  Validation Accuracy 71.25 % valid_num_correct: 2280  valid_num_incorrect: 920\n",
            "epoch completed: 174 loss: 0.9728219925823113  Training Accuracy 74.0703125 %  train_num_correct: 9481  train_num_incorrect: 3319  Validation Accuracy 71.25 % valid_num_correct: 2280  valid_num_incorrect: 920\n",
            "epoch completed: 175 loss: 0.9699638242106791  Training Accuracy 74.1328125 %  train_num_correct: 9489  train_num_incorrect: 3311  Validation Accuracy 71.40625 % valid_num_correct: 2285  valid_num_incorrect: 915\n",
            "epoch completed: 176 loss: 0.9671396649627441  Training Accuracy 74.1640625 %  train_num_correct: 9493  train_num_incorrect: 3307  Validation Accuracy 71.5625 % valid_num_correct: 2290  valid_num_incorrect: 910\n",
            "epoch completed: 177 loss: 0.9643600400044428  Training Accuracy 74.21875 %  train_num_correct: 9500  train_num_incorrect: 3300  Validation Accuracy 71.59375 % valid_num_correct: 2291  valid_num_incorrect: 909\n",
            "epoch completed: 178 loss: 0.9615968336400755  Training Accuracy 74.3125 %  train_num_correct: 9512  train_num_incorrect: 3288  Validation Accuracy 71.78125 % valid_num_correct: 2297  valid_num_incorrect: 903\n",
            "epoch completed: 179 loss: 0.958848619944278  Training Accuracy 74.390625 %  train_num_correct: 9522  train_num_incorrect: 3278  Validation Accuracy 71.78125 % valid_num_correct: 2297  valid_num_incorrect: 903\n",
            "epoch completed: 180 loss: 0.956133973553596  Training Accuracy 74.40625 %  train_num_correct: 9524  train_num_incorrect: 3276  Validation Accuracy 71.8125 % valid_num_correct: 2298  valid_num_incorrect: 902\n",
            "epoch completed: 181 loss: 0.9534324517490039  Training Accuracy 74.46875 %  train_num_correct: 9532  train_num_incorrect: 3268  Validation Accuracy 71.90625 % valid_num_correct: 2301  valid_num_incorrect: 899\n",
            "epoch completed: 182 loss: 0.9507465132965054  Training Accuracy 74.578125 %  train_num_correct: 9546  train_num_incorrect: 3254  Validation Accuracy 72.0 % valid_num_correct: 2304  valid_num_incorrect: 896\n",
            "epoch completed: 183 loss: 0.9480647336162393  Training Accuracy 74.671875 %  train_num_correct: 9558  train_num_incorrect: 3242  Validation Accuracy 72.28125 % valid_num_correct: 2313  valid_num_incorrect: 887\n",
            "epoch completed: 184 loss: 0.9453928199920657  Training Accuracy 74.703125 %  train_num_correct: 9562  train_num_incorrect: 3238  Validation Accuracy 72.34375 % valid_num_correct: 2315  valid_num_incorrect: 885\n",
            "epoch completed: 185 loss: 0.9427545594555017  Training Accuracy 74.7421875 %  train_num_correct: 9567  train_num_incorrect: 3233  Validation Accuracy 72.375 % valid_num_correct: 2316  valid_num_incorrect: 884\n",
            "epoch completed: 186 loss: 0.9401288963951204  Training Accuracy 74.7890625 %  train_num_correct: 9573  train_num_incorrect: 3227  Validation Accuracy 72.4375 % valid_num_correct: 2318  valid_num_incorrect: 882\n",
            "epoch completed: 187 loss: 0.9375274273289935  Training Accuracy 74.859375 %  train_num_correct: 9582  train_num_incorrect: 3218  Validation Accuracy 72.53125 % valid_num_correct: 2321  valid_num_incorrect: 879\n",
            "epoch completed: 188 loss: 0.9349484236591933  Training Accuracy 74.90625 %  train_num_correct: 9588  train_num_incorrect: 3212  Validation Accuracy 72.6875 % valid_num_correct: 2326  valid_num_incorrect: 874\n",
            "epoch completed: 189 loss: 0.9323944120610369  Training Accuracy 74.9296875 %  train_num_correct: 9591  train_num_incorrect: 3209  Validation Accuracy 72.78125 % valid_num_correct: 2329  valid_num_incorrect: 871\n",
            "epoch completed: 190 loss: 0.9298514853274296  Training Accuracy 75.0625 %  train_num_correct: 9608  train_num_incorrect: 3192  Validation Accuracy 72.90625 % valid_num_correct: 2333  valid_num_incorrect: 867\n",
            "epoch completed: 191 loss: 0.9273292469232938  Training Accuracy 75.125 %  train_num_correct: 9616  train_num_incorrect: 3184  Validation Accuracy 72.96875 % valid_num_correct: 2335  valid_num_incorrect: 865\n",
            "epoch completed: 192 loss: 0.9248285682337658  Training Accuracy 75.2265625 %  train_num_correct: 9629  train_num_incorrect: 3171  Validation Accuracy 73.0625 % valid_num_correct: 2338  valid_num_incorrect: 862\n",
            "epoch completed: 193 loss: 0.9223424761583058  Training Accuracy 75.2890625 %  train_num_correct: 9637  train_num_incorrect: 3163  Validation Accuracy 73.09375 % valid_num_correct: 2339  valid_num_incorrect: 861\n",
            "epoch completed: 194 loss: 0.9198756353527816  Training Accuracy 75.40625 %  train_num_correct: 9652  train_num_incorrect: 3148  Validation Accuracy 73.21875 % valid_num_correct: 2343  valid_num_incorrect: 857\n",
            "epoch completed: 195 loss: 0.9174073212588206  Training Accuracy 75.484375 %  train_num_correct: 9662  train_num_incorrect: 3138  Validation Accuracy 73.25 % valid_num_correct: 2344  valid_num_incorrect: 856\n",
            "epoch completed: 196 loss: 0.9149445160613706  Training Accuracy 75.5390625 %  train_num_correct: 9669  train_num_incorrect: 3131  Validation Accuracy 73.28125 % valid_num_correct: 2345  valid_num_incorrect: 855\n",
            "epoch completed: 197 loss: 0.9124877665745926  Training Accuracy 75.59375 %  train_num_correct: 9676  train_num_incorrect: 3124  Validation Accuracy 73.375 % valid_num_correct: 2348  valid_num_incorrect: 852\n",
            "epoch completed: 198 loss: 0.9100300199607793  Training Accuracy 75.6953125 %  train_num_correct: 9689  train_num_incorrect: 3111  Validation Accuracy 73.40625 % valid_num_correct: 2349  valid_num_incorrect: 851\n",
            "epoch completed: 199 loss: 0.907577351830685  Training Accuracy 75.7890625 %  train_num_correct: 9701  train_num_incorrect: 3099  Validation Accuracy 73.5 % valid_num_correct: 2352  valid_num_incorrect: 848\n",
            "epoch completed: 200 loss: 0.9051447079808383  Training Accuracy 75.84375 %  train_num_correct: 9708  train_num_incorrect: 3092  Validation Accuracy 73.5 % valid_num_correct: 2352  valid_num_incorrect: 848\n",
            "epoch completed: 201 loss: 0.9027359118101791  Training Accuracy 75.8828125 %  train_num_correct: 9713  train_num_incorrect: 3087  Validation Accuracy 73.5 % valid_num_correct: 2352  valid_num_incorrect: 848\n",
            "epoch completed: 202 loss: 0.9003573685131936  Training Accuracy 75.9140625 %  train_num_correct: 9717  train_num_incorrect: 3083  Validation Accuracy 73.53125 % valid_num_correct: 2353  valid_num_incorrect: 847\n",
            "epoch completed: 203 loss: 0.8980058409148488  Training Accuracy 76.0 %  train_num_correct: 9728  train_num_incorrect: 3072  Validation Accuracy 73.65625 % valid_num_correct: 2357  valid_num_incorrect: 843\n",
            "epoch completed: 204 loss: 0.8956814095775644  Training Accuracy 76.03125 %  train_num_correct: 9732  train_num_incorrect: 3068  Validation Accuracy 73.75 % valid_num_correct: 2360  valid_num_incorrect: 840\n",
            "epoch completed: 205 loss: 0.893383152870095  Training Accuracy 76.078125 %  train_num_correct: 9738  train_num_incorrect: 3062  Validation Accuracy 73.90625 % valid_num_correct: 2365  valid_num_incorrect: 835\n",
            "epoch completed: 206 loss: 0.8911090171614278  Training Accuracy 76.15625 %  train_num_correct: 9748  train_num_incorrect: 3052  Validation Accuracy 74.0625 % valid_num_correct: 2370  valid_num_incorrect: 830\n",
            "epoch completed: 207 loss: 0.8888315923516472  Training Accuracy 76.234375 %  train_num_correct: 9758  train_num_incorrect: 3042  Validation Accuracy 74.15625 % valid_num_correct: 2373  valid_num_incorrect: 827\n",
            "epoch completed: 208 loss: 0.886587329922298  Training Accuracy 76.234375 %  train_num_correct: 9758  train_num_incorrect: 3042  Validation Accuracy 74.15625 % valid_num_correct: 2373  valid_num_incorrect: 827\n",
            "epoch completed: 209 loss: 0.8843523833453206  Training Accuracy 76.296875 %  train_num_correct: 9766  train_num_incorrect: 3034  Validation Accuracy 74.25 % valid_num_correct: 2376  valid_num_incorrect: 824\n",
            "epoch completed: 210 loss: 0.8821219900797608  Training Accuracy 76.3984375 %  train_num_correct: 9779  train_num_incorrect: 3021  Validation Accuracy 74.3125 % valid_num_correct: 2378  valid_num_incorrect: 822\n",
            "epoch completed: 211 loss: 0.8799225518264236  Training Accuracy 76.4375 %  train_num_correct: 9784  train_num_incorrect: 3016  Validation Accuracy 74.3125 % valid_num_correct: 2378  valid_num_incorrect: 822\n",
            "epoch completed: 212 loss: 0.877745386689282  Training Accuracy 76.5078125 %  train_num_correct: 9793  train_num_incorrect: 3007  Validation Accuracy 74.40625 % valid_num_correct: 2381  valid_num_incorrect: 819\n",
            "epoch completed: 213 loss: 0.8755561122799805  Training Accuracy 76.578125 %  train_num_correct: 9802  train_num_incorrect: 2998  Validation Accuracy 74.40625 % valid_num_correct: 2381  valid_num_incorrect: 819\n",
            "epoch completed: 214 loss: 0.8733694057421765  Training Accuracy 76.59375 %  train_num_correct: 9804  train_num_incorrect: 2996  Validation Accuracy 74.375 % valid_num_correct: 2380  valid_num_incorrect: 820\n",
            "epoch completed: 215 loss: 0.8711875097227195  Training Accuracy 76.6328125 %  train_num_correct: 9809  train_num_incorrect: 2991  Validation Accuracy 74.59375 % valid_num_correct: 2387  valid_num_incorrect: 813\n",
            "epoch completed: 216 loss: 0.8689887640282512  Training Accuracy 76.6640625 %  train_num_correct: 9813  train_num_incorrect: 2987  Validation Accuracy 74.65625 % valid_num_correct: 2389  valid_num_incorrect: 811\n",
            "epoch completed: 217 loss: 0.8668059054206481  Training Accuracy 76.75 %  train_num_correct: 9824  train_num_incorrect: 2976  Validation Accuracy 74.65625 % valid_num_correct: 2389  valid_num_incorrect: 811\n",
            "epoch completed: 218 loss: 0.8646399954220088  Training Accuracy 76.8046875 %  train_num_correct: 9831  train_num_incorrect: 2969  Validation Accuracy 74.65625 % valid_num_correct: 2389  valid_num_incorrect: 811\n",
            "epoch completed: 219 loss: 0.8625118960899998  Training Accuracy 76.8828125 %  train_num_correct: 9841  train_num_incorrect: 2959  Validation Accuracy 74.71875 % valid_num_correct: 2391  valid_num_incorrect: 809\n",
            "epoch completed: 220 loss: 0.8604003928438505  Training Accuracy 76.90625 %  train_num_correct: 9844  train_num_incorrect: 2956  Validation Accuracy 74.875 % valid_num_correct: 2396  valid_num_incorrect: 804\n",
            "epoch completed: 221 loss: 0.8582981866354392  Training Accuracy 76.984375 %  train_num_correct: 9854  train_num_incorrect: 2946  Validation Accuracy 74.90625 % valid_num_correct: 2397  valid_num_incorrect: 803\n",
            "epoch completed: 222 loss: 0.8562005498751134  Training Accuracy 77.078125 %  train_num_correct: 9866  train_num_incorrect: 2934  Validation Accuracy 74.9375 % valid_num_correct: 2398  valid_num_incorrect: 802\n",
            "epoch completed: 223 loss: 0.8541285400302938  Training Accuracy 77.1015625 %  train_num_correct: 9869  train_num_incorrect: 2931  Validation Accuracy 74.90625 % valid_num_correct: 2397  valid_num_incorrect: 803\n",
            "epoch completed: 224 loss: 0.8520731951333412  Training Accuracy 77.1640625 %  train_num_correct: 9877  train_num_incorrect: 2923  Validation Accuracy 75.0 % valid_num_correct: 2400  valid_num_incorrect: 800\n",
            "epoch completed: 225 loss: 0.8500347303675497  Training Accuracy 77.1953125 %  train_num_correct: 9881  train_num_incorrect: 2919  Validation Accuracy 75.15625 % valid_num_correct: 2405  valid_num_incorrect: 795\n",
            "epoch completed: 226 loss: 0.8480078062869731  Training Accuracy 77.2421875 %  train_num_correct: 9887  train_num_incorrect: 2913  Validation Accuracy 75.1875 % valid_num_correct: 2406  valid_num_incorrect: 794\n",
            "epoch completed: 227 loss: 0.8460017363383213  Training Accuracy 77.28125 %  train_num_correct: 9892  train_num_incorrect: 2908  Validation Accuracy 75.28125 % valid_num_correct: 2409  valid_num_incorrect: 791\n",
            "epoch completed: 228 loss: 0.8440010913071788  Training Accuracy 77.375 %  train_num_correct: 9904  train_num_incorrect: 2896  Validation Accuracy 75.40625 % valid_num_correct: 2413  valid_num_incorrect: 787\n",
            "epoch completed: 229 loss: 0.8420306435439538  Training Accuracy 77.4296875 %  train_num_correct: 9911  train_num_incorrect: 2889  Validation Accuracy 75.6875 % valid_num_correct: 2422  valid_num_incorrect: 778\n",
            "epoch completed: 230 loss: 0.8400746976291229  Training Accuracy 77.4765625 %  train_num_correct: 9917  train_num_incorrect: 2883  Validation Accuracy 75.8125 % valid_num_correct: 2426  valid_num_incorrect: 774\n",
            "epoch completed: 231 loss: 0.8381285784672532  Training Accuracy 77.5 %  train_num_correct: 9920  train_num_incorrect: 2880  Validation Accuracy 75.875 % valid_num_correct: 2428  valid_num_incorrect: 772\n",
            "epoch completed: 232 loss: 0.8362089745681008  Training Accuracy 77.5859375 %  train_num_correct: 9931  train_num_incorrect: 2869  Validation Accuracy 75.875 % valid_num_correct: 2428  valid_num_incorrect: 772\n",
            "epoch completed: 233 loss: 0.8342913552248202  Training Accuracy 77.6484375 %  train_num_correct: 9939  train_num_incorrect: 2861  Validation Accuracy 75.90625 % valid_num_correct: 2429  valid_num_incorrect: 771\n",
            "epoch completed: 234 loss: 0.8323965700427209  Training Accuracy 77.7578125 %  train_num_correct: 9953  train_num_incorrect: 2847  Validation Accuracy 75.96875 % valid_num_correct: 2431  valid_num_incorrect: 769\n",
            "epoch completed: 235 loss: 0.8305232274660095  Training Accuracy 77.8203125 %  train_num_correct: 9961  train_num_incorrect: 2839  Validation Accuracy 76.125 % valid_num_correct: 2436  valid_num_incorrect: 764\n",
            "epoch completed: 236 loss: 0.8286419093181335  Training Accuracy 77.921875 %  train_num_correct: 9974  train_num_incorrect: 2826  Validation Accuracy 76.15625 % valid_num_correct: 2437  valid_num_incorrect: 763\n",
            "epoch completed: 237 loss: 0.8267610135368679  Training Accuracy 77.953125 %  train_num_correct: 9978  train_num_incorrect: 2822  Validation Accuracy 76.1875 % valid_num_correct: 2438  valid_num_incorrect: 762\n",
            "epoch completed: 238 loss: 0.8248975529804611  Training Accuracy 77.96875 %  train_num_correct: 9980  train_num_incorrect: 2820  Validation Accuracy 76.21875 % valid_num_correct: 2439  valid_num_incorrect: 761\n",
            "epoch completed: 239 loss: 0.8230449096328856  Training Accuracy 78.0 %  train_num_correct: 9984  train_num_incorrect: 2816  Validation Accuracy 76.25 % valid_num_correct: 2440  valid_num_incorrect: 760\n",
            "epoch completed: 240 loss: 0.8212011025721305  Training Accuracy 78.0703125 %  train_num_correct: 9993  train_num_incorrect: 2807  Validation Accuracy 76.3125 % valid_num_correct: 2442  valid_num_incorrect: 758\n",
            "epoch completed: 241 loss: 0.8193743381684239  Training Accuracy 78.1015625 %  train_num_correct: 9997  train_num_incorrect: 2803  Validation Accuracy 76.375 % valid_num_correct: 2444  valid_num_incorrect: 756\n",
            "epoch completed: 242 loss: 0.8175372636052153  Training Accuracy 78.1796875 %  train_num_correct: 10007  train_num_incorrect: 2793  Validation Accuracy 76.4375 % valid_num_correct: 2446  valid_num_incorrect: 754\n",
            "epoch completed: 243 loss: 0.8157166916060479  Training Accuracy 78.3125 %  train_num_correct: 10024  train_num_incorrect: 2776  Validation Accuracy 76.5 % valid_num_correct: 2448  valid_num_incorrect: 752\n",
            "epoch completed: 244 loss: 0.8139051937099164  Training Accuracy 78.3203125 %  train_num_correct: 10025  train_num_incorrect: 2775  Validation Accuracy 76.5625 % valid_num_correct: 2450  valid_num_incorrect: 750\n",
            "epoch completed: 245 loss: 0.8121096786120732  Training Accuracy 78.34375 %  train_num_correct: 10028  train_num_incorrect: 2772  Validation Accuracy 76.65625 % valid_num_correct: 2453  valid_num_incorrect: 747\n",
            "epoch completed: 246 loss: 0.8103185543517968  Training Accuracy 78.4140625 %  train_num_correct: 10037  train_num_incorrect: 2763  Validation Accuracy 76.71875 % valid_num_correct: 2455  valid_num_incorrect: 745\n",
            "epoch completed: 247 loss: 0.8085340373931073  Training Accuracy 78.4765625 %  train_num_correct: 10045  train_num_incorrect: 2755  Validation Accuracy 76.75 % valid_num_correct: 2456  valid_num_incorrect: 744\n",
            "epoch completed: 248 loss: 0.8067634481383017  Training Accuracy 78.546875 %  train_num_correct: 10054  train_num_incorrect: 2746  Validation Accuracy 76.75 % valid_num_correct: 2456  valid_num_incorrect: 744\n",
            "epoch completed: 249 loss: 0.8049988777818364  Training Accuracy 78.6328125 %  train_num_correct: 10065  train_num_incorrect: 2735  Validation Accuracy 76.8125 % valid_num_correct: 2458  valid_num_incorrect: 742\n",
            "epoch completed: 250 loss: 0.8032536128194708  Training Accuracy 78.6640625 %  train_num_correct: 10069  train_num_incorrect: 2731  Validation Accuracy 76.8125 % valid_num_correct: 2458  valid_num_incorrect: 742\n",
            "epoch completed: 251 loss: 0.8015133478488782  Training Accuracy 78.7109375 %  train_num_correct: 10075  train_num_incorrect: 2725  Validation Accuracy 76.84375 % valid_num_correct: 2459  valid_num_incorrect: 741\n",
            "epoch completed: 252 loss: 0.7997949429810606  Training Accuracy 78.7890625 %  train_num_correct: 10085  train_num_incorrect: 2715  Validation Accuracy 76.96875 % valid_num_correct: 2463  valid_num_incorrect: 737\n",
            "epoch completed: 253 loss: 0.7980981680233028  Training Accuracy 78.828125 %  train_num_correct: 10090  train_num_incorrect: 2710  Validation Accuracy 77.03125 % valid_num_correct: 2465  valid_num_incorrect: 735\n",
            "epoch completed: 254 loss: 0.7963964781435058  Training Accuracy 78.8515625 %  train_num_correct: 10093  train_num_incorrect: 2707  Validation Accuracy 77.0625 % valid_num_correct: 2466  valid_num_incorrect: 734\n",
            "epoch completed: 255 loss: 0.7947118132227072  Training Accuracy 78.8828125 %  train_num_correct: 10097  train_num_incorrect: 2703  Validation Accuracy 77.125 % valid_num_correct: 2468  valid_num_incorrect: 732\n",
            "epoch completed: 256 loss: 0.7930419242212028  Training Accuracy 78.96875 %  train_num_correct: 10108  train_num_incorrect: 2692  Validation Accuracy 77.1875 % valid_num_correct: 2470  valid_num_incorrect: 730\n",
            "epoch completed: 257 loss: 0.7913665957018258  Training Accuracy 79.0 %  train_num_correct: 10112  train_num_incorrect: 2688  Validation Accuracy 77.28125 % valid_num_correct: 2473  valid_num_incorrect: 727\n",
            "epoch completed: 258 loss: 0.7897113963001412  Training Accuracy 79.0 %  train_num_correct: 10112  train_num_incorrect: 2688  Validation Accuracy 77.375 % valid_num_correct: 2476  valid_num_incorrect: 724\n",
            "epoch completed: 259 loss: 0.7880500488749452  Training Accuracy 79.0546875 %  train_num_correct: 10119  train_num_incorrect: 2681  Validation Accuracy 77.40625 % valid_num_correct: 2477  valid_num_incorrect: 723\n",
            "epoch completed: 260 loss: 0.7864074464384556  Training Accuracy 79.0703125 %  train_num_correct: 10121  train_num_incorrect: 2679  Validation Accuracy 77.40625 % valid_num_correct: 2477  valid_num_incorrect: 723\n",
            "epoch completed: 261 loss: 0.7847575171501516  Training Accuracy 79.109375 %  train_num_correct: 10126  train_num_incorrect: 2674  Validation Accuracy 77.375 % valid_num_correct: 2476  valid_num_incorrect: 724\n",
            "epoch completed: 262 loss: 0.7831373014641972  Training Accuracy 79.1015625 %  train_num_correct: 10125  train_num_incorrect: 2675  Validation Accuracy 77.40625 % valid_num_correct: 2477  valid_num_incorrect: 723\n",
            "epoch completed: 263 loss: 0.7815135407694804  Training Accuracy 79.15625 %  train_num_correct: 10132  train_num_incorrect: 2668  Validation Accuracy 77.4375 % valid_num_correct: 2478  valid_num_incorrect: 722\n",
            "epoch completed: 264 loss: 0.7799053940167013  Training Accuracy 79.21875 %  train_num_correct: 10140  train_num_incorrect: 2660  Validation Accuracy 77.5 % valid_num_correct: 2480  valid_num_incorrect: 720\n",
            "epoch completed: 265 loss: 0.7783022614894775  Training Accuracy 79.2734375 %  train_num_correct: 10147  train_num_incorrect: 2653  Validation Accuracy 77.53125 % valid_num_correct: 2481  valid_num_incorrect: 719\n",
            "epoch completed: 266 loss: 0.776714290750222  Training Accuracy 79.3203125 %  train_num_correct: 10153  train_num_incorrect: 2647  Validation Accuracy 77.5625 % valid_num_correct: 2482  valid_num_incorrect: 718\n",
            "epoch completed: 267 loss: 0.7751360038436684  Training Accuracy 79.359375 %  train_num_correct: 10158  train_num_incorrect: 2642  Validation Accuracy 77.59375 % valid_num_correct: 2483  valid_num_incorrect: 717\n",
            "epoch completed: 268 loss: 0.7735696246423742  Training Accuracy 79.3828125 %  train_num_correct: 10161  train_num_incorrect: 2639  Validation Accuracy 77.625 % valid_num_correct: 2484  valid_num_incorrect: 716\n",
            "epoch completed: 269 loss: 0.7720098425618409  Training Accuracy 79.390625 %  train_num_correct: 10162  train_num_incorrect: 2638  Validation Accuracy 77.6875 % valid_num_correct: 2486  valid_num_incorrect: 714\n",
            "epoch completed: 270 loss: 0.7704587946179768  Training Accuracy 79.4296875 %  train_num_correct: 10167  train_num_incorrect: 2633  Validation Accuracy 77.84375 % valid_num_correct: 2491  valid_num_incorrect: 709\n",
            "epoch completed: 271 loss: 0.7689212656822414  Training Accuracy 79.421875 %  train_num_correct: 10166  train_num_incorrect: 2634  Validation Accuracy 77.90625 % valid_num_correct: 2493  valid_num_incorrect: 707\n",
            "epoch completed: 272 loss: 0.7673944761421667  Training Accuracy 79.4296875 %  train_num_correct: 10167  train_num_incorrect: 2633  Validation Accuracy 78.0 % valid_num_correct: 2496  valid_num_incorrect: 704\n",
            "epoch completed: 273 loss: 0.7658760041502406  Training Accuracy 79.453125 %  train_num_correct: 10170  train_num_incorrect: 2630  Validation Accuracy 78.03125 % valid_num_correct: 2497  valid_num_incorrect: 703\n",
            "epoch completed: 274 loss: 0.7643696006854657  Training Accuracy 79.4921875 %  train_num_correct: 10175  train_num_incorrect: 2625  Validation Accuracy 78.09375 % valid_num_correct: 2499  valid_num_incorrect: 701\n",
            "epoch completed: 275 loss: 0.7628588435911284  Training Accuracy 79.515625 %  train_num_correct: 10178  train_num_incorrect: 2622  Validation Accuracy 78.125 % valid_num_correct: 2500  valid_num_incorrect: 700\n",
            "epoch completed: 276 loss: 0.7613485636962958  Training Accuracy 79.5078125 %  train_num_correct: 10177  train_num_incorrect: 2623  Validation Accuracy 78.1875 % valid_num_correct: 2502  valid_num_incorrect: 698\n",
            "epoch completed: 277 loss: 0.7598412049034922  Training Accuracy 79.5234375 %  train_num_correct: 10179  train_num_incorrect: 2621  Validation Accuracy 78.1875 % valid_num_correct: 2502  valid_num_incorrect: 698\n",
            "epoch completed: 278 loss: 0.758338338083576  Training Accuracy 79.5625 %  train_num_correct: 10184  train_num_incorrect: 2616  Validation Accuracy 78.21875 % valid_num_correct: 2503  valid_num_incorrect: 697\n",
            "epoch completed: 279 loss: 0.7568307626684956  Training Accuracy 79.578125 %  train_num_correct: 10186  train_num_incorrect: 2614  Validation Accuracy 78.25 % valid_num_correct: 2504  valid_num_incorrect: 696\n",
            "epoch completed: 280 loss: 0.7553402708782473  Training Accuracy 79.6171875 %  train_num_correct: 10191  train_num_incorrect: 2609  Validation Accuracy 78.28125 % valid_num_correct: 2505  valid_num_incorrect: 695\n",
            "epoch completed: 281 loss: 0.7538580992856286  Training Accuracy 79.6328125 %  train_num_correct: 10193  train_num_incorrect: 2607  Validation Accuracy 78.375 % valid_num_correct: 2508  valid_num_incorrect: 692\n",
            "epoch completed: 282 loss: 0.7523872386211578  Training Accuracy 79.625 %  train_num_correct: 10192  train_num_incorrect: 2608  Validation Accuracy 78.40625 % valid_num_correct: 2509  valid_num_incorrect: 691\n",
            "epoch completed: 283 loss: 0.7509162309188813  Training Accuracy 79.671875 %  train_num_correct: 10198  train_num_incorrect: 2602  Validation Accuracy 78.375 % valid_num_correct: 2508  valid_num_incorrect: 692\n",
            "epoch completed: 284 loss: 0.7494656239355832  Training Accuracy 79.6875 %  train_num_correct: 10200  train_num_incorrect: 2600  Validation Accuracy 78.4375 % valid_num_correct: 2510  valid_num_incorrect: 690\n",
            "epoch completed: 285 loss: 0.7480248773583709  Training Accuracy 79.6953125 %  train_num_correct: 10201  train_num_incorrect: 2599  Validation Accuracy 78.4375 % valid_num_correct: 2510  valid_num_incorrect: 690\n",
            "epoch completed: 286 loss: 0.746598164939091  Training Accuracy 79.75 %  train_num_correct: 10208  train_num_incorrect: 2592  Validation Accuracy 78.53125 % valid_num_correct: 2513  valid_num_incorrect: 687\n",
            "epoch completed: 287 loss: 0.7451716396936716  Training Accuracy 79.7734375 %  train_num_correct: 10211  train_num_incorrect: 2589  Validation Accuracy 78.5625 % valid_num_correct: 2514  valid_num_incorrect: 686\n",
            "epoch completed: 288 loss: 0.7437561497705092  Training Accuracy 79.7890625 %  train_num_correct: 10213  train_num_incorrect: 2587  Validation Accuracy 78.5 % valid_num_correct: 2512  valid_num_incorrect: 688\n",
            "epoch completed: 289 loss: 0.7423479058663124  Training Accuracy 79.78125 %  train_num_correct: 10212  train_num_incorrect: 2588  Validation Accuracy 78.59375 % valid_num_correct: 2515  valid_num_incorrect: 685\n",
            "epoch completed: 290 loss: 0.74094246024795  Training Accuracy 79.8125 %  train_num_correct: 10216  train_num_incorrect: 2584  Validation Accuracy 78.65625 % valid_num_correct: 2517  valid_num_incorrect: 683\n",
            "epoch completed: 291 loss: 0.7395538718305003  Training Accuracy 79.8515625 %  train_num_correct: 10221  train_num_incorrect: 2579  Validation Accuracy 78.78125 % valid_num_correct: 2521  valid_num_incorrect: 679\n",
            "epoch completed: 292 loss: 0.7381770468277519  Training Accuracy 79.875 %  train_num_correct: 10224  train_num_incorrect: 2576  Validation Accuracy 78.84375 % valid_num_correct: 2523  valid_num_incorrect: 677\n",
            "epoch completed: 293 loss: 0.7368051664760028  Training Accuracy 79.9296875 %  train_num_correct: 10231  train_num_incorrect: 2569  Validation Accuracy 78.8125 % valid_num_correct: 2522  valid_num_incorrect: 678\n",
            "epoch completed: 294 loss: 0.7354412383536222  Training Accuracy 79.953125 %  train_num_correct: 10234  train_num_incorrect: 2566  Validation Accuracy 78.9375 % valid_num_correct: 2526  valid_num_incorrect: 674\n",
            "epoch completed: 295 loss: 0.7340902361140883  Training Accuracy 79.9765625 %  train_num_correct: 10237  train_num_incorrect: 2563  Validation Accuracy 79.03125 % valid_num_correct: 2529  valid_num_incorrect: 671\n",
            "epoch completed: 296 loss: 0.7327385565635945  Training Accuracy 80.0078125 %  train_num_correct: 10241  train_num_incorrect: 2559  Validation Accuracy 79.03125 % valid_num_correct: 2529  valid_num_incorrect: 671\n",
            "epoch completed: 297 loss: 0.7313980434248716  Training Accuracy 80.0390625 %  train_num_correct: 10245  train_num_incorrect: 2555  Validation Accuracy 79.0625 % valid_num_correct: 2530  valid_num_incorrect: 670\n",
            "epoch completed: 298 loss: 0.730068622537422  Training Accuracy 80.046875 %  train_num_correct: 10246  train_num_incorrect: 2554  Validation Accuracy 79.0625 % valid_num_correct: 2530  valid_num_incorrect: 670\n",
            "epoch completed: 299 loss: 0.7287526054691658  Training Accuracy 80.1015625 %  train_num_correct: 10253  train_num_incorrect: 2547  Validation Accuracy 79.125 % valid_num_correct: 2532  valid_num_incorrect: 668\n",
            "epoch completed: 300 loss: 0.7274389487240268  Training Accuracy 80.1171875 %  train_num_correct: 10255  train_num_incorrect: 2545  Validation Accuracy 79.1875 % valid_num_correct: 2534  valid_num_incorrect: 666\n",
            "epoch completed: 301 loss: 0.7261230794609803  Training Accuracy 80.1484375 %  train_num_correct: 10259  train_num_incorrect: 2541  Validation Accuracy 79.1875 % valid_num_correct: 2534  valid_num_incorrect: 666\n",
            "epoch completed: 302 loss: 0.7248141860538675  Training Accuracy 80.1953125 %  train_num_correct: 10265  train_num_incorrect: 2535  Validation Accuracy 79.21875 % valid_num_correct: 2535  valid_num_incorrect: 665\n",
            "epoch completed: 303 loss: 0.7235143530994412  Training Accuracy 80.21875 %  train_num_correct: 10268  train_num_incorrect: 2532  Validation Accuracy 79.28125 % valid_num_correct: 2537  valid_num_incorrect: 663\n",
            "epoch completed: 304 loss: 0.7222295348309153  Training Accuracy 80.234375 %  train_num_correct: 10270  train_num_incorrect: 2530  Validation Accuracy 79.28125 % valid_num_correct: 2537  valid_num_incorrect: 663\n",
            "epoch completed: 305 loss: 0.7209417043163139  Training Accuracy 80.2578125 %  train_num_correct: 10273  train_num_incorrect: 2527  Validation Accuracy 79.34375 % valid_num_correct: 2539  valid_num_incorrect: 661\n",
            "epoch completed: 306 loss: 0.7196576304202675  Training Accuracy 80.2890625 %  train_num_correct: 10277  train_num_incorrect: 2523  Validation Accuracy 79.375 % valid_num_correct: 2540  valid_num_incorrect: 660\n",
            "epoch completed: 307 loss: 0.7183840253795424  Training Accuracy 80.3046875 %  train_num_correct: 10279  train_num_incorrect: 2521  Validation Accuracy 79.40625 % valid_num_correct: 2541  valid_num_incorrect: 659\n",
            "epoch completed: 308 loss: 0.7171117308305948  Training Accuracy 80.3828125 %  train_num_correct: 10289  train_num_incorrect: 2511  Validation Accuracy 79.46875 % valid_num_correct: 2543  valid_num_incorrect: 657\n",
            "epoch completed: 309 loss: 0.7158380005688716  Training Accuracy 80.40625 %  train_num_correct: 10292  train_num_incorrect: 2508  Validation Accuracy 79.5 % valid_num_correct: 2544  valid_num_incorrect: 656\n",
            "epoch completed: 310 loss: 0.7145761266553622  Training Accuracy 80.4765625 %  train_num_correct: 10301  train_num_incorrect: 2499  Validation Accuracy 79.46875 % valid_num_correct: 2543  valid_num_incorrect: 657\n",
            "epoch completed: 311 loss: 0.7133164864082129  Training Accuracy 80.4921875 %  train_num_correct: 10303  train_num_incorrect: 2497  Validation Accuracy 79.5 % valid_num_correct: 2544  valid_num_incorrect: 656\n",
            "epoch completed: 312 loss: 0.7120712397313899  Training Accuracy 80.5 %  train_num_correct: 10304  train_num_incorrect: 2496  Validation Accuracy 79.5 % valid_num_correct: 2544  valid_num_incorrect: 656\n",
            "epoch completed: 313 loss: 0.7108232992042551  Training Accuracy 80.5234375 %  train_num_correct: 10307  train_num_incorrect: 2493  Validation Accuracy 79.5 % valid_num_correct: 2544  valid_num_incorrect: 656\n",
            "epoch completed: 314 loss: 0.7095815089572634  Training Accuracy 80.5703125 %  train_num_correct: 10313  train_num_incorrect: 2487  Validation Accuracy 79.5 % valid_num_correct: 2544  valid_num_incorrect: 656\n",
            "epoch completed: 315 loss: 0.7083518719072184  Training Accuracy 80.546875 %  train_num_correct: 10310  train_num_incorrect: 2490  Validation Accuracy 79.53125 % valid_num_correct: 2545  valid_num_incorrect: 655\n",
            "epoch completed: 316 loss: 0.7071272617936525  Training Accuracy 80.5703125 %  train_num_correct: 10313  train_num_incorrect: 2487  Validation Accuracy 79.53125 % valid_num_correct: 2545  valid_num_incorrect: 655\n",
            "epoch completed: 317 loss: 0.7059022219803155  Training Accuracy 80.609375 %  train_num_correct: 10318  train_num_incorrect: 2482  Validation Accuracy 79.5625 % valid_num_correct: 2546  valid_num_incorrect: 654\n",
            "epoch completed: 318 loss: 0.704673840893495  Training Accuracy 80.6640625 %  train_num_correct: 10325  train_num_incorrect: 2475  Validation Accuracy 79.6875 % valid_num_correct: 2550  valid_num_incorrect: 650\n",
            "epoch completed: 319 loss: 0.7034477238416837  Training Accuracy 80.71875 %  train_num_correct: 10332  train_num_incorrect: 2468  Validation Accuracy 79.71875 % valid_num_correct: 2551  valid_num_incorrect: 649\n",
            "epoch completed: 320 loss: 0.7022348102247671  Training Accuracy 80.765625 %  train_num_correct: 10338  train_num_incorrect: 2462  Validation Accuracy 79.6875 % valid_num_correct: 2550  valid_num_incorrect: 650\n",
            "epoch completed: 321 loss: 0.7010281751382916  Training Accuracy 80.78125 %  train_num_correct: 10340  train_num_incorrect: 2460  Validation Accuracy 79.71875 % valid_num_correct: 2551  valid_num_incorrect: 649\n",
            "epoch completed: 322 loss: 0.6998304643968365  Training Accuracy 80.796875 %  train_num_correct: 10342  train_num_incorrect: 2458  Validation Accuracy 79.71875 % valid_num_correct: 2551  valid_num_incorrect: 649\n",
            "epoch completed: 323 loss: 0.6986332747151051  Training Accuracy 80.84375 %  train_num_correct: 10348  train_num_incorrect: 2452  Validation Accuracy 79.75 % valid_num_correct: 2552  valid_num_incorrect: 648\n",
            "epoch completed: 324 loss: 0.6974291036830275  Training Accuracy 80.84375 %  train_num_correct: 10348  train_num_incorrect: 2452  Validation Accuracy 79.78125 % valid_num_correct: 2553  valid_num_incorrect: 647\n",
            "epoch completed: 325 loss: 0.6962424533171501  Training Accuracy 80.8671875 %  train_num_correct: 10351  train_num_incorrect: 2449  Validation Accuracy 79.78125 % valid_num_correct: 2553  valid_num_incorrect: 647\n",
            "epoch completed: 326 loss: 0.6950625000557128  Training Accuracy 80.9453125 %  train_num_correct: 10361  train_num_incorrect: 2439  Validation Accuracy 79.78125 % valid_num_correct: 2553  valid_num_incorrect: 647\n",
            "epoch completed: 327 loss: 0.6938862665102163  Training Accuracy 81.0 %  train_num_correct: 10368  train_num_incorrect: 2432  Validation Accuracy 79.90625 % valid_num_correct: 2557  valid_num_incorrect: 643\n",
            "epoch completed: 328 loss: 0.6927181412229539  Training Accuracy 81.046875 %  train_num_correct: 10374  train_num_incorrect: 2426  Validation Accuracy 80.0 % valid_num_correct: 2560  valid_num_incorrect: 640\n",
            "epoch completed: 329 loss: 0.6915517726446231  Training Accuracy 81.09375 %  train_num_correct: 10380  train_num_incorrect: 2420  Validation Accuracy 80.0 % valid_num_correct: 2560  valid_num_incorrect: 640\n",
            "epoch completed: 330 loss: 0.6903944572925711  Training Accuracy 81.125 %  train_num_correct: 10384  train_num_incorrect: 2416  Validation Accuracy 80.03125 % valid_num_correct: 2561  valid_num_incorrect: 639\n",
            "epoch completed: 331 loss: 0.6892487879958357  Training Accuracy 81.15625 %  train_num_correct: 10388  train_num_incorrect: 2412  Validation Accuracy 80.125 % valid_num_correct: 2564  valid_num_incorrect: 636\n",
            "epoch completed: 332 loss: 0.6881022889580157  Training Accuracy 81.1875 %  train_num_correct: 10392  train_num_incorrect: 2408  Validation Accuracy 80.125 % valid_num_correct: 2564  valid_num_incorrect: 636\n",
            "epoch completed: 333 loss: 0.6869613394781517  Training Accuracy 81.2109375 %  train_num_correct: 10395  train_num_incorrect: 2405  Validation Accuracy 80.15625 % valid_num_correct: 2565  valid_num_incorrect: 635\n",
            "epoch completed: 334 loss: 0.6858208784768633  Training Accuracy 81.2578125 %  train_num_correct: 10401  train_num_incorrect: 2399  Validation Accuracy 80.1875 % valid_num_correct: 2566  valid_num_incorrect: 634\n",
            "epoch completed: 335 loss: 0.6846928544243966  Training Accuracy 81.28125 %  train_num_correct: 10404  train_num_incorrect: 2396  Validation Accuracy 80.21875 % valid_num_correct: 2567  valid_num_incorrect: 633\n",
            "epoch completed: 336 loss: 0.6835623568623536  Training Accuracy 81.2734375 %  train_num_correct: 10403  train_num_incorrect: 2397  Validation Accuracy 80.25 % valid_num_correct: 2568  valid_num_incorrect: 632\n",
            "epoch completed: 337 loss: 0.6824468554122183  Training Accuracy 81.28125 %  train_num_correct: 10404  train_num_incorrect: 2396  Validation Accuracy 80.3125 % valid_num_correct: 2570  valid_num_incorrect: 630\n",
            "epoch completed: 338 loss: 0.6813202194568779  Training Accuracy 81.3359375 %  train_num_correct: 10411  train_num_incorrect: 2389  Validation Accuracy 80.3125 % valid_num_correct: 2570  valid_num_incorrect: 630\n",
            "epoch completed: 339 loss: 0.6801877028805279  Training Accuracy 81.3515625 %  train_num_correct: 10413  train_num_incorrect: 2387  Validation Accuracy 80.34375 % valid_num_correct: 2571  valid_num_incorrect: 629\n",
            "epoch completed: 340 loss: 0.6790647409674035  Training Accuracy 81.359375 %  train_num_correct: 10414  train_num_incorrect: 2386  Validation Accuracy 80.40625 % valid_num_correct: 2573  valid_num_incorrect: 627\n",
            "epoch completed: 341 loss: 0.6779482718534059  Training Accuracy 81.3828125 %  train_num_correct: 10417  train_num_incorrect: 2383  Validation Accuracy 80.4375 % valid_num_correct: 2574  valid_num_incorrect: 626\n",
            "epoch completed: 342 loss: 0.6768398930505216  Training Accuracy 81.3984375 %  train_num_correct: 10419  train_num_incorrect: 2381  Validation Accuracy 80.53125 % valid_num_correct: 2577  valid_num_incorrect: 623\n",
            "epoch completed: 343 loss: 0.675743875748353  Training Accuracy 81.40625 %  train_num_correct: 10420  train_num_incorrect: 2380  Validation Accuracy 80.5625 % valid_num_correct: 2578  valid_num_incorrect: 622\n",
            "epoch completed: 344 loss: 0.6746466699512566  Training Accuracy 81.4296875 %  train_num_correct: 10423  train_num_incorrect: 2377  Validation Accuracy 80.625 % valid_num_correct: 2580  valid_num_incorrect: 620\n",
            "epoch completed: 345 loss: 0.6735522315027156  Training Accuracy 81.4765625 %  train_num_correct: 10429  train_num_incorrect: 2371  Validation Accuracy 80.6875 % valid_num_correct: 2582  valid_num_incorrect: 618\n",
            "epoch completed: 346 loss: 0.6724739089769985  Training Accuracy 81.4921875 %  train_num_correct: 10431  train_num_incorrect: 2369  Validation Accuracy 80.71875 % valid_num_correct: 2583  valid_num_incorrect: 617\n",
            "epoch completed: 347 loss: 0.6713868635105559  Training Accuracy 81.53125 %  train_num_correct: 10436  train_num_incorrect: 2364  Validation Accuracy 80.75 % valid_num_correct: 2584  valid_num_incorrect: 616\n",
            "epoch completed: 348 loss: 0.6703158569814086  Training Accuracy 81.53125 %  train_num_correct: 10436  train_num_incorrect: 2364  Validation Accuracy 80.78125 % valid_num_correct: 2585  valid_num_incorrect: 615\n",
            "epoch completed: 349 loss: 0.6692533296625192  Training Accuracy 81.5390625 %  train_num_correct: 10437  train_num_incorrect: 2363  Validation Accuracy 80.78125 % valid_num_correct: 2585  valid_num_incorrect: 615\n",
            "epoch completed: 350 loss: 0.6681971761496247  Training Accuracy 81.5703125 %  train_num_correct: 10441  train_num_incorrect: 2359  Validation Accuracy 80.8125 % valid_num_correct: 2586  valid_num_incorrect: 614\n",
            "epoch completed: 351 loss: 0.6671390144627992  Training Accuracy 81.6015625 %  train_num_correct: 10445  train_num_incorrect: 2355  Validation Accuracy 80.875 % valid_num_correct: 2588  valid_num_incorrect: 612\n",
            "epoch completed: 352 loss: 0.666073670401618  Training Accuracy 81.625 %  train_num_correct: 10448  train_num_incorrect: 2352  Validation Accuracy 80.9375 % valid_num_correct: 2590  valid_num_incorrect: 610\n",
            "epoch completed: 353 loss: 0.6650154505625713  Training Accuracy 81.65625 %  train_num_correct: 10452  train_num_incorrect: 2348  Validation Accuracy 80.96875 % valid_num_correct: 2591  valid_num_incorrect: 609\n",
            "epoch completed: 354 loss: 0.6639540769995882  Training Accuracy 81.671875 %  train_num_correct: 10454  train_num_incorrect: 2346  Validation Accuracy 81.0 % valid_num_correct: 2592  valid_num_incorrect: 608\n",
            "epoch completed: 355 loss: 0.6628937239519347  Training Accuracy 81.6875 %  train_num_correct: 10456  train_num_incorrect: 2344  Validation Accuracy 81.0 % valid_num_correct: 2592  valid_num_incorrect: 608\n",
            "epoch completed: 356 loss: 0.6618219935358222  Training Accuracy 81.703125 %  train_num_correct: 10458  train_num_incorrect: 2342  Validation Accuracy 81.0625 % valid_num_correct: 2594  valid_num_incorrect: 606\n",
            "epoch completed: 357 loss: 0.6607604666303801  Training Accuracy 81.734375 %  train_num_correct: 10462  train_num_incorrect: 2338  Validation Accuracy 81.0625 % valid_num_correct: 2594  valid_num_incorrect: 606\n",
            "epoch completed: 358 loss: 0.6597223324693086  Training Accuracy 81.7890625 %  train_num_correct: 10469  train_num_incorrect: 2331  Validation Accuracy 81.0625 % valid_num_correct: 2594  valid_num_incorrect: 606\n",
            "epoch completed: 359 loss: 0.6586687384818964  Training Accuracy 81.796875 %  train_num_correct: 10470  train_num_incorrect: 2330  Validation Accuracy 81.09375 % valid_num_correct: 2595  valid_num_incorrect: 605\n",
            "epoch completed: 360 loss: 0.65762585150421  Training Accuracy 81.8515625 %  train_num_correct: 10477  train_num_incorrect: 2323  Validation Accuracy 81.125 % valid_num_correct: 2596  valid_num_incorrect: 604\n",
            "epoch completed: 361 loss: 0.6565932879964208  Training Accuracy 81.890625 %  train_num_correct: 10482  train_num_incorrect: 2318  Validation Accuracy 81.15625 % valid_num_correct: 2597  valid_num_incorrect: 603\n",
            "epoch completed: 362 loss: 0.6555729626806392  Training Accuracy 81.9140625 %  train_num_correct: 10485  train_num_incorrect: 2315  Validation Accuracy 81.1875 % valid_num_correct: 2598  valid_num_incorrect: 602\n",
            "epoch completed: 363 loss: 0.6545453599170855  Training Accuracy 81.9375 %  train_num_correct: 10488  train_num_incorrect: 2312  Validation Accuracy 81.1875 % valid_num_correct: 2598  valid_num_incorrect: 602\n",
            "epoch completed: 364 loss: 0.6535414251120933  Training Accuracy 81.953125 %  train_num_correct: 10490  train_num_incorrect: 2310  Validation Accuracy 81.1875 % valid_num_correct: 2598  valid_num_incorrect: 602\n",
            "epoch completed: 365 loss: 0.6525343381979661  Training Accuracy 81.9609375 %  train_num_correct: 10491  train_num_incorrect: 2309  Validation Accuracy 81.3125 % valid_num_correct: 2602  valid_num_incorrect: 598\n",
            "epoch completed: 366 loss: 0.6515222042279147  Training Accuracy 81.9765625 %  train_num_correct: 10493  train_num_incorrect: 2307  Validation Accuracy 81.40625 % valid_num_correct: 2605  valid_num_incorrect: 595\n",
            "epoch completed: 367 loss: 0.6505150228787262  Training Accuracy 81.9921875 %  train_num_correct: 10495  train_num_incorrect: 2305  Validation Accuracy 81.46875 % valid_num_correct: 2607  valid_num_incorrect: 593\n",
            "epoch completed: 368 loss: 0.6495226744696252  Training Accuracy 82.015625 %  train_num_correct: 10498  train_num_incorrect: 2302  Validation Accuracy 81.5 % valid_num_correct: 2608  valid_num_incorrect: 592\n",
            "epoch completed: 369 loss: 0.6485237981752945  Training Accuracy 82.0 %  train_num_correct: 10496  train_num_incorrect: 2304  Validation Accuracy 81.5 % valid_num_correct: 2608  valid_num_incorrect: 592\n",
            "epoch completed: 370 loss: 0.6475457844561063  Training Accuracy 82.03125 %  train_num_correct: 10500  train_num_incorrect: 2300  Validation Accuracy 81.53125 % valid_num_correct: 2609  valid_num_incorrect: 591\n",
            "epoch completed: 371 loss: 0.6465617472956231  Training Accuracy 82.078125 %  train_num_correct: 10506  train_num_incorrect: 2294  Validation Accuracy 81.53125 % valid_num_correct: 2609  valid_num_incorrect: 591\n",
            "epoch completed: 372 loss: 0.6455844036962141  Training Accuracy 82.1015625 %  train_num_correct: 10509  train_num_incorrect: 2291  Validation Accuracy 81.5625 % valid_num_correct: 2610  valid_num_incorrect: 590\n",
            "epoch completed: 373 loss: 0.6446155371083669  Training Accuracy 82.125 %  train_num_correct: 10512  train_num_incorrect: 2288  Validation Accuracy 81.59375 % valid_num_correct: 2611  valid_num_incorrect: 589\n",
            "epoch completed: 374 loss: 0.6436477254018943  Training Accuracy 82.15625 %  train_num_correct: 10516  train_num_incorrect: 2284  Validation Accuracy 81.625 % valid_num_correct: 2612  valid_num_incorrect: 588\n",
            "epoch completed: 375 loss: 0.6426764693762906  Training Accuracy 82.1484375 %  train_num_correct: 10515  train_num_incorrect: 2285  Validation Accuracy 81.65625 % valid_num_correct: 2613  valid_num_incorrect: 587\n",
            "epoch completed: 376 loss: 0.6417112705953906  Training Accuracy 82.1796875 %  train_num_correct: 10519  train_num_incorrect: 2281  Validation Accuracy 81.65625 % valid_num_correct: 2613  valid_num_incorrect: 587\n",
            "epoch completed: 377 loss: 0.6407509026574578  Training Accuracy 82.25 %  train_num_correct: 10528  train_num_incorrect: 2272  Validation Accuracy 81.6875 % valid_num_correct: 2614  valid_num_incorrect: 586\n",
            "epoch completed: 378 loss: 0.6397917858239408  Training Accuracy 82.28125 %  train_num_correct: 10532  train_num_incorrect: 2268  Validation Accuracy 81.6875 % valid_num_correct: 2614  valid_num_incorrect: 586\n",
            "epoch completed: 379 loss: 0.638842903473433  Training Accuracy 82.265625 %  train_num_correct: 10530  train_num_incorrect: 2270  Validation Accuracy 81.75 % valid_num_correct: 2616  valid_num_incorrect: 584\n",
            "epoch completed: 380 loss: 0.6378872522643964  Training Accuracy 82.3125 %  train_num_correct: 10536  train_num_incorrect: 2264  Validation Accuracy 81.75 % valid_num_correct: 2616  valid_num_incorrect: 584\n",
            "epoch completed: 381 loss: 0.6369461358960936  Training Accuracy 82.3125 %  train_num_correct: 10536  train_num_incorrect: 2264  Validation Accuracy 81.78125 % valid_num_correct: 2617  valid_num_incorrect: 583\n",
            "epoch completed: 382 loss: 0.6360072840959924  Training Accuracy 82.3203125 %  train_num_correct: 10537  train_num_incorrect: 2263  Validation Accuracy 81.75 % valid_num_correct: 2616  valid_num_incorrect: 584\n",
            "epoch completed: 383 loss: 0.6350774311773327  Training Accuracy 82.359375 %  train_num_correct: 10542  train_num_incorrect: 2258  Validation Accuracy 81.78125 % valid_num_correct: 2617  valid_num_incorrect: 583\n",
            "epoch completed: 384 loss: 0.6341514648036571  Training Accuracy 82.3984375 %  train_num_correct: 10547  train_num_incorrect: 2253  Validation Accuracy 81.78125 % valid_num_correct: 2617  valid_num_incorrect: 583\n",
            "epoch completed: 385 loss: 0.6332162036074831  Training Accuracy 82.40625 %  train_num_correct: 10548  train_num_incorrect: 2252  Validation Accuracy 81.78125 % valid_num_correct: 2617  valid_num_incorrect: 583\n",
            "epoch completed: 386 loss: 0.6322966031645912  Training Accuracy 82.4296875 %  train_num_correct: 10551  train_num_incorrect: 2249  Validation Accuracy 81.8125 % valid_num_correct: 2618  valid_num_incorrect: 582\n",
            "epoch completed: 387 loss: 0.6313846347217382  Training Accuracy 82.515625 %  train_num_correct: 10562  train_num_incorrect: 2238  Validation Accuracy 81.84375 % valid_num_correct: 2619  valid_num_incorrect: 581\n",
            "epoch completed: 388 loss: 0.630471302174055  Training Accuracy 82.5390625 %  train_num_correct: 10565  train_num_incorrect: 2235  Validation Accuracy 81.9375 % valid_num_correct: 2622  valid_num_incorrect: 578\n",
            "epoch completed: 389 loss: 0.6295613501274313  Training Accuracy 82.6015625 %  train_num_correct: 10573  train_num_incorrect: 2227  Validation Accuracy 82.0 % valid_num_correct: 2624  valid_num_incorrect: 576\n",
            "epoch completed: 390 loss: 0.6286468066090819  Training Accuracy 82.640625 %  train_num_correct: 10578  train_num_incorrect: 2222  Validation Accuracy 82.0 % valid_num_correct: 2624  valid_num_incorrect: 576\n",
            "epoch completed: 391 loss: 0.6277396551304372  Training Accuracy 82.6640625 %  train_num_correct: 10581  train_num_incorrect: 2219  Validation Accuracy 82.0625 % valid_num_correct: 2626  valid_num_incorrect: 574\n",
            "epoch completed: 392 loss: 0.6268280477559117  Training Accuracy 82.6953125 %  train_num_correct: 10585  train_num_incorrect: 2215  Validation Accuracy 82.15625 % valid_num_correct: 2629  valid_num_incorrect: 571\n",
            "epoch completed: 393 loss: 0.6259304045638843  Training Accuracy 82.7109375 %  train_num_correct: 10587  train_num_incorrect: 2213  Validation Accuracy 82.15625 % valid_num_correct: 2629  valid_num_incorrect: 571\n",
            "epoch completed: 394 loss: 0.62503175003974  Training Accuracy 82.7265625 %  train_num_correct: 10589  train_num_incorrect: 2211  Validation Accuracy 82.1875 % valid_num_correct: 2630  valid_num_incorrect: 570\n",
            "epoch completed: 395 loss: 0.6241321822840395  Training Accuracy 82.7890625 %  train_num_correct: 10597  train_num_incorrect: 2203  Validation Accuracy 82.15625 % valid_num_correct: 2629  valid_num_incorrect: 571\n",
            "epoch completed: 396 loss: 0.6232376209032925  Training Accuracy 82.8203125 %  train_num_correct: 10601  train_num_incorrect: 2199  Validation Accuracy 82.15625 % valid_num_correct: 2629  valid_num_incorrect: 571\n",
            "epoch completed: 397 loss: 0.6223475169173114  Training Accuracy 82.8515625 %  train_num_correct: 10605  train_num_incorrect: 2195  Validation Accuracy 82.15625 % valid_num_correct: 2629  valid_num_incorrect: 571\n",
            "epoch completed: 398 loss: 0.6214554322199138  Training Accuracy 82.890625 %  train_num_correct: 10610  train_num_incorrect: 2190  Validation Accuracy 82.15625 % valid_num_correct: 2629  valid_num_incorrect: 571\n",
            "epoch completed: 399 loss: 0.6205615765506759  Training Accuracy 82.90625 %  train_num_correct: 10612  train_num_incorrect: 2188  Validation Accuracy 82.21875 % valid_num_correct: 2631  valid_num_incorrect: 569\n",
            "epoch completed: 400 loss: 0.6196843656384305  Training Accuracy 82.90625 %  train_num_correct: 10612  train_num_incorrect: 2188  Validation Accuracy 82.25 % valid_num_correct: 2632  valid_num_incorrect: 568\n",
            "epoch completed: 401 loss: 0.6188054286604722  Training Accuracy 82.921875 %  train_num_correct: 10614  train_num_incorrect: 2186  Validation Accuracy 82.25 % valid_num_correct: 2632  valid_num_incorrect: 568\n",
            "epoch completed: 402 loss: 0.617929006546563  Training Accuracy 82.9296875 %  train_num_correct: 10615  train_num_incorrect: 2185  Validation Accuracy 82.28125 % valid_num_correct: 2633  valid_num_incorrect: 567\n",
            "epoch completed: 403 loss: 0.6170638277810554  Training Accuracy 82.953125 %  train_num_correct: 10618  train_num_incorrect: 2182  Validation Accuracy 82.28125 % valid_num_correct: 2633  valid_num_incorrect: 567\n",
            "epoch completed: 404 loss: 0.6161861872093987  Training Accuracy 82.953125 %  train_num_correct: 10618  train_num_incorrect: 2182  Validation Accuracy 82.28125 % valid_num_correct: 2633  valid_num_incorrect: 567\n",
            " Test Accuracy 81.89999999999999 % test_num_correct: 3276  test_num_incorrect: 724\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j4A5-UITYBSb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}